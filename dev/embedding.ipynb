{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from models.file import File, FileType\n",
    "from service.embedding import EmbeddingService\n",
    "from termcolor import colored\n",
    "\n",
    "PINECONE_INDEX = os.getenv(\"PINECONE_INDEX\", \"\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"\")\n",
    "PINECONE_HOST = os.getenv(\"PINECONE_HOST\", \"\")\n",
    "\n",
    "file = File(\n",
    "    type=FileType.pdf,\n",
    "    url=\"https://arxiv.org/pdf/2402.05131.pdf\"\n",
    ")\n",
    "vector_credentials = {\n",
    "        \"type\": \"pinecone\",\n",
    "        \"config\": {\n",
    "            \"api_key\": PINECONE_API_KEY,\n",
    "            \"host\": PINECONE_HOST,\n",
    "        }\n",
    "    },\n",
    "\n",
    "embedding_service = EmbeddingService(\n",
    "        files=[file],\n",
    "        index_name=PINECONE_INDEX,\n",
    "        vector_credentials=vector_credentials\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = await embedding_service.generate_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the documents\n",
    "doc_texts = [doc.text for doc in docs]\n",
    "concatenated_text = \" \".join([doc.text for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "nltk_sentences = [sent_tokenize(concatenated_text)]\n",
    "flattened_nltk_sentences = [sentence for sublist in nltk_sentences for sentence in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_router.utils import splitters\n",
    "from semantic_router.encoders.openai import OpenAIEncoder\n",
    "\n",
    "encoder = OpenAIEncoder()\n",
    "\n",
    "threshold = 0.68  # Adjust this value based on your needs\n",
    "\n",
    "# Apply the semantic splitter\n",
    "# takes around 4 minutes\n",
    "semantic_splits = splitters.semantic_splitter(\n",
    "    encoder=encoder,\n",
    "    docs=flattened_nltk_sentences,\n",
    "    threshold=threshold,\n",
    "    split_method=\"cumulative_similarity_drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_semantic_splits = [doc for split in semantic_splits for doc in split.docs]\n",
    "flattened_semantic_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_chunks = await embedding_service.generate_chunks(docs)\n",
    "naive_chunks_text = [chunk.text for chunk in naive_chunks]\n",
    "naive_chunks_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_colored_chunks(chunks):\n",
    "    colors = ['red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white']\n",
    "    concatenated_document = \"\"\n",
    "\n",
    "    # Check if the first element is a list (indicating a list of lists)\n",
    "    # If so, flatten it. Otherwise, proceed with the assumption it's a flat list.\n",
    "    if chunks and isinstance(chunks[0], list):\n",
    "        flat_chunks = [sentence for chunk in chunks for sentence in chunk]\n",
    "    else:\n",
    "        flat_chunks = chunks\n",
    "\n",
    "    for i, chunk in enumerate(flat_chunks):\n",
    "        color = colors[i % len(colors)]\n",
    "        # Use HTML span with style for coloring\n",
    "        colored_text = f'<span style=\"color: {color};\">{chunk}</span>'\n",
    "        concatenated_document += colored_text + \" \"\n",
    "\n",
    "    return concatenated_document\n",
    "\n",
    "def compare_chunking_strategies_side_by_side(nltk_sentences, naive_chunks, semantic_splits):\n",
    "    nltk_result = print_colored_chunks(nltk_sentences)\n",
    "    naive_result = print_colored_chunks(naive_chunks)\n",
    "    semantic_result = print_colored_chunks(semantic_splits)\n",
    "\n",
    "    display(HTML(f\"\"\"\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>NLTK Sentences</th>\n",
    "            <th>Semantic Splits</th>\n",
    "            <th>Naive Chunks</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left;\">{nltk_result}</td>\n",
    "            <td style=\"text-align: left;\">{semantic_result}</td>\n",
    "            <td style=\"text-align: left;\">{naive_result}</td>\n",
    "        </tr>\n",
    "        </tr>\n",
    "    </table>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "        <tr>\n",
       "            <th>NLTK Sentences</th>\n",
       "            <th>Semantic Splits</th>\n",
       "            <th>Naive Chunks</th>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td style=\"text-align: left;\"><span style=\"color: red;\">arXiv:2402.05131v1  [cs.CL]  5 Feb 2024Financial Report Chunking for Eﬀective\n",
       "Retrieval Augmented Generation\n",
       "Antonio Jimeno Yepes, Yao You, Jan Milczek, Sebastian Laverde, an d Leah Li\n",
       "Unstructured Technologies\n",
       "Sacramento, CA, USA\n",
       "leah@unstructured.io\n",
       "https://unstructured.io\n",
       "Abstract.</span> <span style=\"color: green;\">Chunking information is a key step in Retrieval Augmented\n",
       "Generation (RAG).</span> <span style=\"color: yellow;\">Current research primarily centers on pa ragraph-\n",
       "level chunking.</span> <span style=\"color: blue;\">This approach treats all texts as equal and n eglects\n",
       "the information contained in the structure of documents.</span> <span style=\"color: magenta;\">We propose\n",
       "an expanded approach to chunk documents by moving beyond mer e\n",
       "paragraph-level chunking to chunk primary by structural el ement com-\n",
       "ponents of documents.</span> <span style=\"color: cyan;\">Dissecting documents into these cons tituent ele-\n",
       "ments creates a new way to chunk documents that yields the bes t chunk\n",
       "size without tuning.</span> <span style=\"color: white;\">We introduce a novel framework that eva luates how\n",
       "chunking based on element types annotated by document under standing\n",
       "models contributes to the overall context and accuracy of th e informa-\n",
       "tion retrieved.</span> <span style=\"color: red;\">We also demonstrate how this approach impac ts RAG\n",
       "assisted Question & Answer task performance.</span> <span style=\"color: green;\">Our research i ncludes a\n",
       "comprehensive analysis of various element types, their rol e in eﬀective\n",
       "information retrieval, and the impact they have on the quali ty of RAG\n",
       "outputs.</span> <span style=\"color: yellow;\">Findings support that element type based chunking largely im-\n",
       "prove RAG results on ﬁnancial reporting.</span> <span style=\"color: blue;\">Through this resea rch, we are\n",
       "also able to answer how to uncover highly accurate RAG.</span> <span style=\"color: magenta;\">Keywords: Retrieval Augmented Generation ·Document Chunking ·\n",
       "Document Pre-Processing ·Financial Domain ·Large Language Models\n",
       "1 Introduction\n",
       "Existing approaches for document understanding use a combination n of methods\n",
       "from the computer vision and natural language processing domains to identify\n",
       "the diﬀerent components in a document.</span> <span style=\"color: cyan;\">In the rapidly evolving lands cape of\n",
       "artiﬁcial intelligence, the capability to eﬀectively process unstruct ured data is\n",
       "becoming increasingly critical.</span> <span style=\"color: white;\">Large Language Models (LLMs) like GPT -4 have\n",
       "revolutionized natural language understanding and generation, a s evidenced by\n",
       "their prompt-based functionalities [31], enabling a wide range of applic ations [5].</span> <span style=\"color: red;\">However,the eﬃcacyofthese models is often constrainedby their relianceon the\n",
       "size and quality of the data they process.</span> <span style=\"color: green;\">A notable limitation is the re stricted\n",
       "contextualwindowofLLMs,whichhamperstheirabilitytofullycompr ehendthe 2 Jimeno Yepes et al.</span> <span style=\"color: yellow;\">contents of extensive documents [25,22,18].</span> <span style=\"color: blue;\">By dissecting large vo lumes of text\n",
       "into smaller, more focused segments, LLMs can process each part with greater\n",
       "precision, ensuring a thorough understanding of each section.</span> <span style=\"color: magenta;\">Th is segmented\n",
       "approach allows for meticulous analysis of unstructured data, ena bling LLMs to\n",
       "construct a more comprehensive and coherent understanding of the entire docu-\n",
       "meant [41].</span> <span style=\"color: cyan;\">There remains a challenge in ensuring factual accuracy an d relevance\n",
       "in the generated responses, especially when dealing with complex or e xtensive\n",
       "information.</span> <span style=\"color: white;\">Recently, Retrieval Augmented Generation (RAG) [21,12] has been devel-\n",
       "oped to address the hallucination problem with LLMs [15,43] when recovering\n",
       "factual information directly from an LLM.</span> <span style=\"color: red;\">In RAG, instead of answe ring a user\n",
       "query directly using an LLM, the user query is used to retrieve docu ments or\n",
       "segments from a corpus and the top retrieved documents or segm ents are used\n",
       "to generate the answer in conjunction with an LLM.</span> <span style=\"color: green;\">In this way, RAG con-\n",
       "straints the answer to the set of retrieved documents.</span> <span style=\"color: yellow;\">RAGs hav e been used as\n",
       "well to answer questions from single documents [14].</span> <span style=\"color: blue;\">The document s are split\n",
       "into smaller parts or chunks, indexed by a retrieval system and rec overed and\n",
       "processed depending on the user information need.</span> <span style=\"color: magenta;\">In a sense, th is processallows\n",
       "answering questions about information in a single document, thus co ntributing\n",
       "to the set of techniques available for document understanding.</span> <span style=\"color: cyan;\">Since documents need to be chunked for RAG processing, this raises the\n",
       "question about what is the best practice to chunk documents for e ﬀective RAG\n",
       "document understanding.</span> <span style=\"color: white;\">There are several dimensions to consid er when decid-\n",
       "ing how to chunk a document, which includes the size of the chunks.</span> <span style=\"color: red;\">The retrieval system in RAG can use traditional retrieval systems using bag-\n",
       "of-words methods or a vector database.</span> <span style=\"color: green;\">If a vector database is used, then an\n",
       "embedding needs to be obtained from each chunk, thus the number of tokens\n",
       "in the chunk is relevant since the neural networks processing the c hunks might\n",
       "have constraints on the number of tokens.</span> <span style=\"color: yellow;\">As well, diﬀerent chunk sizes might\n",
       "have undesirable retrieval results.</span> <span style=\"color: blue;\">Since the most relevant retrie ved chunks need\n",
       "to be processed by an LLM, the number of tokens in retrieved chun ks might\n",
       "have an eﬀect in the generation of the answer [25].</span> <span style=\"color: magenta;\">As we see, chunk ing is re-\n",
       "quired for RAG systems and there are several advantages and dis advantages\n",
       "when considering how to chunk a document.</span> <span style=\"color: cyan;\">In this work, we study speciﬁcally the chunking of U.S. Securities and Ex-\n",
       "change Commission (SEC)1Financial Reports2, including 10-Ks, 10-Qs, and\n",
       "8-Ks.</span> <span style=\"color: white;\">This study plays a critical role in oﬀering insights into the ﬁnanc ial health\n",
       "and operational dynamics of public companies.</span> <span style=\"color: red;\">These documents pr esent unique\n",
       "challenges in terms of document processing and information extract tion as they\n",
       "consist of varying sizes and layouts, and contain a variety of tabula r informa-\n",
       "tion.</span> <span style=\"color: green;\">Previous work has evaluated the processing of these report s with simple\n",
       "chunking strategies (e.g., tokens), but we believe that a more eﬀec tive use of\n",
       "these reports might be achieved by a better pre-processing of th e documents\n",
       "1https://www.sec.gov\n",
       "2https://www.sec.gov/files/cf-frm.pdf Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 3\n",
       "and chunking conﬁguration3[14].</span> <span style=\"color: yellow;\">To the best of our knowledge, this is the ﬁrst\n",
       "systematic study on chunking for document understanding and mo re speciﬁcally\n",
       "for processing ﬁnancial reports.</span> <span style=\"color: blue;\">2 Related work\n",
       "RAG is an innovative method that has emerged to enhance the perfo rmance of\n",
       "LLMs by incorporating external knowledge, thereby boosting the ir capabilities.</span> <span style=\"color: magenta;\">This technique has undergone substantial research, examining va rious conﬁgu-\n",
       "rations and applications.</span> <span style=\"color: cyan;\">Key research includes Gao et al.’s [12] detaile d analysis\n",
       "of RAG conﬁgurations and their role in enhancing Natural Language Processing\n",
       "(NLP) tasks, reducing errors, and improving factual accuracy.</span> <span style=\"color: white;\">Several context\n",
       "retrieval methods are proposed to dynamically retrieve document s to improve\n",
       "the coherence of generated outputs [1].</span> <span style=\"color: red;\">Other research introdu ced advancements\n",
       "in RAG, including reasoning chain storage and optimization strategies for re-\n",
       "trieval, respectively, broadening the scope and eﬃciency of RAG ap plications in\n",
       "LLMs[21].MorerecentworkhascomparedRAGvsLLMﬁne-tuning,a ndidenti-\n",
       "ﬁed that applying both improves the performance of each individual method [2].</span> <span style=\"color: green;\">Chunkinghasbeen identiﬁed asthe keyfactorinthe successofRAG ,improv-\n",
       "ing the relevance of retrieved content by ensuring accurate embe dding of text\n",
       "with minimal noise.</span> <span style=\"color: yellow;\">Various strategies have been developed for text subdivision,\n",
       "each with its unique approach.</span> <span style=\"color: blue;\">They can be summarized as follows: th eﬁxed\n",
       "size strategy divides text into uniform segments, but it often overlooks the\n",
       "underlying textual structure.</span> <span style=\"color: magenta;\">In contrast, the recursive strategy iteratively\n",
       "subdivides text using separators like punctuation marks, allowing it t o adapt\n",
       "more ﬂuidly to the content.</span> <span style=\"color: cyan;\">The contextual strategy takes this a step further\n",
       "by employing NLP techniques such as sentence segmentation to rep resent the\n",
       "meaning in context.</span> <span style=\"color: white;\">Lastly, the hybrid strategy combines diﬀerent approaches,\n",
       "oﬀering greater ﬂexibility in handling diverse text types [34].</span> <span style=\"color: red;\">Howeve r, an area\n",
       "yet to be explored in RAG chunking based on element types (document t struc-\n",
       "ture), which involves analyzing the inherent structure of document ts, such as\n",
       "headings, paragraphs, tables, to guide the chunking process.</span> <span style=\"color: green;\">Alt hough chunk-\n",
       "ing by Markdown and LaTeX comes closer to addressing element type s, it’s not\n",
       "the same in nature as a dedicated approach that directly considers document\n",
       "structure and element types for chunking, which could potentially y ield more\n",
       "contextually relevant chunks.</span> <span style=\"color: yellow;\">Exploring the structure of ﬁnancial reports is an exceptional are a for es-\n",
       "tablishing optimal principles for chunking.</span> <span style=\"color: blue;\">The intricate nature of do cument\n",
       "structures and contents has resulted in most of the work process sing ﬁnancial\n",
       "reports focusing on the identiﬁcation of structural elements.</span> <span style=\"color: magenta;\">Am ong previous\n",
       "work, we ﬁnd El-Haj et al.</span> <span style=\"color: cyan;\">[10] and the FinTOC challenges [17,4,11] th at have\n",
       "worked at the document structure level for UK and French ﬁnanc ial reports.</span> <span style=\"color: white;\">Ad-\n",
       "3https://www.cnbc.com/2023/12/19/gpt-and-other-ai-mo dels-cant-analyze-\n",
       "an-sec-filing-researchers-find.html 4 Jimeno Yepes et al.</span> <span style=\"color: red;\">ditionally, there is recent work that considers U.S. SEC reports, wh ich includes\n",
       "DocLayNet [33] and more speciﬁcally with the report tables in FinTabN et [45].</span> <span style=\"color: green;\">On the side of ﬁnancial models, there is work in sentiment analysis in ﬁ-\n",
       "nance [37], which includes the pre-training of specialised models such a s Fin-\n",
       "BERT by Liu et al.</span> <span style=\"color: yellow;\">[26], which is a BERT based model pre-trained on large\n",
       "corpora including large collections of ﬁnancial news collected from diﬀ erent sites\n",
       "and FinBERT by DeSola et al, [9] trained on Wikipedia, BookCorpus and U .S.</span> <span style=\"color: blue;\">SEC data.</span> <span style=\"color: magenta;\">Additional models include BloombergGPT [40], FinGPT [42] and\n",
       "Instruct-FinGPT[44].</span> <span style=\"color: cyan;\">MoreadvancedatasetsintheﬁnancialdomainincludeFinQA[6],LLMWa re[27],\n",
       "ConFIRM [8] and TAT-QA [46] among others [7,38,19] that have been p repared\n",
       "for retrieval and or Questions and Answering (Q&A) tasks over sn ippets of ﬁ-\n",
       "nancial data that includes tabular data, which has allowed methods o n large\n",
       "language models to be tested on them [39].</span> <span style=\"color: white;\">Most of the previous work has focused on understanding the layout t of ﬁ-\n",
       "nancial documents or understanding speciﬁc snippets of existing r eports with\n",
       "diﬀerent levels of complexity, but there has not been much researc h in under-\n",
       "standingﬁnancialreportdocuments,exceptsomemorerecentw orkthatincludes\n",
       "FinanceBench [14], in which a set of questions about the content of ﬁ nancial re-\n",
       "ports are proposed that includes the evidence snippet.</span> <span style=\"color: red;\">More speciﬁcally on document chunking methods for RAG, there are stan-\n",
       "dard approaches being considered such as chunking text into span s of a given\n",
       "token length (e.g.</span> <span style=\"color: green;\">128 and 256) or chunking based on sentences.</span> <span style=\"color: yellow;\">O pen source\n",
       "projects already allow simple processing of documents (e.g.</span> <span style=\"color: blue;\">Unstru ctured4, Lla-\n",
       "maindex5or Langchain6), without explicitly considering the table structure on\n",
       "which these chunking strategies are applied.</span> <span style=\"color: magenta;\">Even though diﬀerent approaches are available, an exhaustive eva luation of\n",
       "chunking applied to RAG and speciﬁcally to ﬁnancial reporting, excep t for some\n",
       "limited chunking analysis [14,36], is non-existent.</span> <span style=\"color: cyan;\">In our work, we comp are a\n",
       "broad range of chunking approachesin addition to more simple ones a nd provide\n",
       "an analysis of the outcomes of diﬀerent methods when asking quest ions about\n",
       "diﬀerent aspects of the reports.</span> <span style=\"color: white;\">3 Methods\n",
       "In this section, wepresentthe chunkingstrategiesthat we havee valuated.</span> <span style=\"color: red;\">Before\n",
       "describing the chunking strategies, we present the RAG environme nt in which\n",
       "these strategies have been evaluated and the dataset used for e valuation.</span> <span style=\"color: green;\">3.1 RAG setting for the experiments\n",
       "The RAG pipeline used to process a user question is presented in ﬁgur e 1 and is\n",
       "a common instance ofa RAG [12].</span> <span style=\"color: yellow;\">Priorto answeringany question abo ut a given\n",
       "4https://unstructured.io\n",
       "5https://www.llamaindex.ai\n",
       "6https://www.langchain.com Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 5\n",
       "document, the document is split into chunks and the chunks are inde xed into\n",
       "a vector database (vectordb).</span> <span style=\"color: blue;\">When a question is sent to the RAG system, the\n",
       "top-k chunks most similar to the question are retrieved from the ve ctor database\n",
       "and used to generate the answer using a large language model as ge nerator.</span> <span style=\"color: magenta;\">In\n",
       "order to retrieve chunks from the vector database, the questio n is encoded into a\n",
       "vector that is compared to the vector previously generated from the chunks.</span> <span style=\"color: cyan;\">To\n",
       "prompt the generator, the question is converted into a set of inst ructions that\n",
       "instruct the LLM to ﬁnd the answer within the top-k retrieved chun ks.</span> <span style=\"color: white;\">Fig.1.RAG steps to answer a question about a document\n",
       "In our experiments, we modify the way documents are chunked prior to\n",
       "being indexed in the vector database.</span> <span style=\"color: red;\">All other settings remain con stant.</span> <span style=\"color: green;\">In the\n",
       "following sections, we describe in more detail each one of the compon ents and\n",
       "processes used.</span> <span style=\"color: yellow;\">3.2 Indexing and retrieval\n",
       "We have used the open source system Weaviate7as our vector database.</span> <span style=\"color: blue;\">As\n",
       "encoder model, we have used a sentence transformer [35] trained on over 256M\n",
       "questions and answers, which is available from the HuggingFace syst em8.</span> <span style=\"color: magenta;\">As shown in ﬁgure 2, to index a document, ﬁrst the document is split in to\n",
       "chunks, then each chunk is processed by an encoder model and th en indexed into\n",
       "the vector database.</span> <span style=\"color: cyan;\">Based on the chunking strategy a document t will be split\n",
       "into a larger or smaller set of chunks.</span> <span style=\"color: white;\">Fig.2.Indexing of document chunks into the vector database\n",
       "7https://weaviate.io/developers/weaviate\n",
       "8https://huggingface.co/sentence-transformers/multi- qa-mpnet-base-dot-\n",
       "v1 6 Jimeno Yepes et al.</span> <span style=\"color: red;\">As shown in ﬁgure 1, to retrievechunks relevant to a question, the question is\n",
       "converted into a vector representation and the vector database e returns a ranked\n",
       "list of chunks based on the similarity between question vector and th e chunks\n",
       "in the database.</span> <span style=\"color: green;\">Weaviate implements an approximate nearest neigh bours algo-\n",
       "rhythm [28] as their retrieval approach, which supports fast retrie val with high\n",
       "accuracy.</span> <span style=\"color: yellow;\">In our experiments, we retrieve the top-10 chunks fo r each question.</span> <span style=\"color: blue;\">3.3 Generation\n",
       "Once the vector database has retrieved the top-10 chunks base d on a question,\n",
       "the generation module generates the answer.</span> <span style=\"color: magenta;\">To do so, a prompt b ased on the\n",
       "question and the retrieved chunks are provided to a large language model that\n",
       "generates the answer of the system.</span> <span style=\"color: cyan;\">WehaveusedGPT-4[31]asthegenerator,whichhasshownbestpe rformance\n",
       "compared to earlier versions.</span> <span style=\"color: white;\">As well, its performance was better c ompared to\n",
       "existing open source alternatives [22] such as Mixtral [16].</span> <span style=\"color: red;\">We used t he prompt\n",
       "presented in ﬁgure 3 that we designed on another similar RAG implement tation\n",
       "with diﬀerent document types.</span> <span style=\"color: green;\">The prompt conditions the answer t o the query\n",
       "and the chunks, referred to as source, and if the generator cannot answer it\n",
       "should return No answer .</span> <span style=\"color: yellow;\">please answer the question below by referencing the list of s ources\n",
       "provided after the question; if the question can not be answe red just\n",
       "respond ’No answer’.</span> <span style=\"color: blue;\">The sources are listed after \"Sources: \".</span> <span style=\"color: magenta;\">Question: {query}\n",
       "Sources: {key} - {source}\n",
       "...\n",
       "Fig.3.Example prompt template used by the generator\n",
       "3.4 Chunking\n",
       "As a baseline chunking method, we have split the documents into chun ks of size\n",
       "ntokens (n∈ {128,256,512}).</span> <span style=\"color: cyan;\">As well, an aggregation of the output by the\n",
       "indexing of diﬀerent chunking conﬁgurations has been considered.</span> <span style=\"color: white;\">In addition to chunking based on the number of tokens, we have pro cessed\n",
       "the documents using computer vision and natural language process singto extract\n",
       "elements identiﬁed in the reports.</span> <span style=\"color: red;\">The list of elements considered ar e provided\n",
       "by the Unstructured9open source library.</span> <span style=\"color: green;\">From the set of processing strategies,\n",
       "9https://unstructured-io.github.io/unstructured/intr oduction.html#\n",
       "elements Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 7\n",
       "we use Chipper, a vision encoder decoder10model inspired by Donut [20] to\n",
       "showcase the performance diﬀerence.</span> <span style=\"color: yellow;\">The Chipper model output s results as a\n",
       "JSON representation of the document, listing elements per page ch aracterized\n",
       "by their element type.</span> <span style=\"color: blue;\">Additionally, Chipper provides a bounding box e nclosing\n",
       "each element on the page and the corresponding element text.</span> <span style=\"color: magenta;\">These elements are sometimes short to be considered as chunks, s o to gen-\n",
       "erate chunks from elements the following steps have been followed.</span> <span style=\"color: cyan;\">Given the\n",
       "structureofﬁnancereportingdocuments,ourstructuralchu nkingeﬀortsarecon-\n",
       "centrated on processing titles, texts, and tables.</span> <span style=\"color: white;\">The steps to g enerate element-\n",
       "based chunks are:\n",
       "–if the element text length is smaller than 2,048 characters, a merge w ith the\n",
       "following element is attempted\n",
       "–iteratively, element texts are merged following the step above till eit her the\n",
       "desired length is achieved, without breaking the element\n",
       "–if a title element is found, a new chunk is started\n",
       "–if a table element is found, a new chunk is started, preservingthe en tire table\n",
       "After element-based chunks have been derived, three types of m etadata are\n",
       "generated to enrich the content and support eﬃcient indexing.</span> <span style=\"color: red;\">Th e ﬁrst two\n",
       "types, generated via predeﬁned prompt templates with GPT-4, inc lude: 1) up to\n",
       "6 representative keywords of the composite chunk 2) a summarise d paragraph\n",
       "of the composite chunk.</span> <span style=\"color: green;\">The third type is 3) Naive representation u sing the ﬁrst\n",
       "two sentences from a composite chunk (a kind of preﬁx) and in the c ase oftables,\n",
       "the description of the table, which is typically identiﬁed in the table cap tion.</span> <span style=\"color: yellow;\">3.5 Dataset\n",
       "To evaluate the performance of the diﬀerent chunking approache s, we have used\n",
       "the FinanceBenchdataset [14].</span> <span style=\"color: blue;\">FinanceBench is anew benchmarking datasetde-\n",
       "signed to assess the capabilities of LLMs in answering open-book ﬁna ncial ques-\n",
       "tions.</span> <span style=\"color: magenta;\">The questions collected are realistic and applicable to real-wor ld ﬁnancial\n",
       "scenarios and include complex questions that require computationa l reasoning\n",
       "to arrive at conclusive answers.</span> <span style=\"color: cyan;\">This dataset is made of 150 instances with questions and answers fr om 84\n",
       "unique reports.</span> <span style=\"color: white;\">The dataset does not include the source document ts, which we\n",
       "have downloaded.</span> <span style=\"color: red;\">We were able to recover only 80 documents, which reduces\n",
       "the number of questions to 141 from the original 150.</span> <span style=\"color: green;\">The distribut ion of Un-\n",
       "structured elements predictions are shown in table 1.</span> <span style=\"color: yellow;\">Documents have a varying number of pages, spanning from 4 pages (FOOT-\n",
       "LOCKER 20228Kdated-2022-05-20) to 549 pages (e.g.</span> <span style=\"color: blue;\">PEPSICO 202110K),\n",
       "with an average of 147.34 with std 97.78 with a total of 11,787 pages c ombined.</span> <span style=\"color: magenta;\">Each instance contains a link to the report, the question, a questio n type , the\n",
       "answerand supportingevidence,with pagenumberwherethe evide nce islocated\n",
       "10https://huggingface.co/docs/transformers/model_doc/ vision-encoder-\n",
       "decoder 8 Jimeno Yepes et al.</span> <span style=\"color: cyan;\">Table 1.</span> <span style=\"color: white;\">Unstructured element types distribution for Chipper predictions against doc-\n",
       "uments in FinanceBench.</span> <span style=\"color: red;\">Element Type Chipper Entities\n",
       "NarrativeText 61,780\n",
       "Title 29,664\n",
       "ListItem 33,054\n",
       "UncategorizedText 9,400\n",
       "Footer 1,026\n",
       "Table 7,700\n",
       "Header 3,959\n",
       "Image 26\n",
       "FigureCaption 54\n",
       "Formula 29\n",
       "Address 229\n",
       "Total 146,921\n",
       "in the document, that allows for a closer evaluation of the results.</span> <span style=\"color: green;\">B ased on the\n",
       "page number, evidence contexts are located in diﬀerent areas in th e documents,\n",
       "ranging from the ﬁrst page in some cases up to page 304 in one instan ce.</span> <span style=\"color: yellow;\">The\n",
       "mean page number to ﬁnd the evidence is 54.58 with a standard deviat ion of\n",
       "43.66, which shows that evidence contexts to answer the question s are spread\n",
       "within a document.</span> <span style=\"color: blue;\">These characteristics make FinanceBench a per fect dataset\n",
       "for evaluating RAG.</span> <span style=\"color: magenta;\">An example instance is available in table 2.</span> <span style=\"color: cyan;\">4 Results\n",
       "Inthissection,weevaluatethediﬀerentchunkingstrategiesusing theFinanceBench\n",
       "dataset.</span> <span style=\"color: white;\">Our evaluation is grounded in factual accuracy, which allow ws us to mea-\n",
       "sure the eﬀectiveness of each conﬁguration by its precision in retr ieving answers\n",
       "that match the ground truth, as well as its generation abilities.</span> <span style=\"color: red;\">We are considering 80 documents and 141 questions from FinanceBe nch.</span> <span style=\"color: green;\">Using the OpenAI tokenizer from the model text-embedding-ada-002 that uses\n",
       "the tokenizer cl100kbase11, there are on average 102,444.35 tokens with std of\n",
       "61,979.45, which shows the large variability of document lengths as se en by the\n",
       "diﬀerent number of pages per document presented above.</span> <span style=\"color: yellow;\">Chunking Eﬃciency The ﬁrst thing we analyzed is the total number of\n",
       "chunks, as it impacts indexing time.</span> <span style=\"color: blue;\">We would like to observe the relatio nship\n",
       "between accuracy and total chunk size.</span> <span style=\"color: magenta;\">Table 3 shows the number of chunks\n",
       "derived from each one of the processing methods.</span> <span style=\"color: cyan;\">Unstructured element-based\n",
       "chunks are closer in size to Base 512, and as the chunk size decrease es for the\n",
       "basic chunking strategies, the total number of chunks increases linearly.</span> <span style=\"color: white;\">11https://platform.openai.com/docs/guides/embeddings/ limitations-risks Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 9\n",
       "Table 2.</span> <span style=\"color: red;\">Example question from the FinanceBench dataset\n",
       "Field Value\n",
       "ﬁnancebench idﬁnancebench id00859\n",
       "docname VERIZON 202110K\n",
       "doclink https://www.verizon.com/about/sites/default/ﬁles/20 21-Annual-\n",
       "Report-on-Form-10-K.pdf\n",
       "question type’novel-generated’\n",
       "question Among all of the derivative instruments that Verizon used to manage\n",
       "the exposure to ﬂuctuations of foreign currencies exchange rates or\n",
       "interest rates, which one had the highest notional value in F Y 2021?</span> <span style=\"color: green;\">answer Cross currency swaps.</span> <span style=\"color: yellow;\">Its notional value was $32,502 million.,\n",
       "evidence textDerivative Instruments We enter into derivative transacti owns primarily\n",
       "to manage our exposure to ﬂuctuations in foreign currency ex change\n",
       "rates and interest rates.</span> <span style=\"color: blue;\">We employ risk management strateg ies, which\n",
       "may include the use of a variety of derivatives including int erest rate\n",
       "swaps, cross currency swaps, forward starting interest rat e swaps, trea-\n",
       "sury rate locks, interest rate caps, swaptions and foreign e xchange for-\n",
       "wards.</span> <span style=\"color: magenta;\">We do not hold derivatives for trading purposes.</span> <span style=\"color: cyan;\">The f ollowing\n",
       "table sets forth the notional amounts of our outstanding der ivative in-\n",
       "struments: (dollars in millions) AtDecember 31, 2021 2020 I nterestrate\n",
       "swaps $19,779 $17,768 Cross currency swaps 32,502 26,288 Forward\n",
       "starting interest rate swaps 1,000 2,000 Foreign exchange f orwards 932\n",
       "1,405\n",
       "pagenumber 85\n",
       "Table 3.</span> <span style=\"color: white;\">Chunks statistics for basic chunking elements and Unstruct ured elements\n",
       "Processing total chunks mean chunks per document (std) tables mean (std)\n",
       "Base 128 64,058 800.73 (484.11) N/A\n",
       "Base 256 32,051 400.64 (242.04) N/A\n",
       "Base 512 16,046 200.58 (121.01) N/A\n",
       "Chipper 20,843 260.57 (145.80) 96.20 (57.53)\n",
       "Retrieval Accuracy Secondly, we evaluate the capabilities of each chunking\n",
       "strategy in terms of retrieval accuracy.</span> <span style=\"color: red;\">We use the page number s in the ground\n",
       "truth to calculate the page-level retrieval accuracy, and we use ROGUE [24] and\n",
       "BLEU [32] scores to evaluate the accuracy of paragraph-levelre trieval compared\n",
       "to the ground truth evidence paragraphs.</span> <span style=\"color: green;\">As shown in Table 4, when compared to Unstructured element-base d chunk-\n",
       "ing strategies, basic chunking strategies seem to have higher page -level retrieval\n",
       "accuracy but lower paragraph-level accuracy on average.</span> <span style=\"color: yellow;\">Addit ionally, basic\n",
       "chunking strategies also lack consistency between page-level and paragraph-level\n",
       "accuracy; higher page-level accuracy doesn’t ensure higher par agraph-level ac-\n",
       "curacy.</span> <span style=\"color: blue;\">For example, Base 128 has the second highest page-level accuracy but 10 Jimeno Yepes et al.</span> <span style=\"color: magenta;\">the lowest paragraph-level scores among all.</span> <span style=\"color: cyan;\">On the other hand, e lement-based\n",
       "chunking strategies showed more consistent results.</span> <span style=\"color: white;\">A fascinating discovery is that when various chunking strategies ar e com-\n",
       "bined, it results in enhanced retrieval scores, achieving superior p performance\n",
       "at both the page level (84.4%) and paragraph level (with ROGUE at 0 .568%\n",
       "and BLEU at 0.452%).</span> <span style=\"color: red;\">This ﬁnding addresses an unresolved question : how to\n",
       "improve the accuracy of RAG.</span> <span style=\"color: green;\">The element based method provides the highest scores and it also pr ovides a\n",
       "mechanism to chunk documents without the need to ﬁne tune hyper -parameters\n",
       "like the number of tokens in a chunk.</span> <span style=\"color: yellow;\">This suggests the element base d method\n",
       "is more generalizable and can be applied to new types of documents.</span> <span style=\"color: blue;\">Q&A Accuracy Third, we evaluate the Q&Aaccuracyfor the chunking strate-\n",
       "gies.Inadditiontomanualevaluation,wehaveinvestigatedanauto maticevalua-\n",
       "tionusingGPT-4.GPT-4compareshowtheanswersprovidedbyour methodare\n",
       "similar to or diﬀerent from the FinanceBench gold standard, similar ap proaches\n",
       "have been previously evaluated [13,23,29,30].</span> <span style=\"color: magenta;\">The automatic evaluatio n allows\n",
       "scaling the evaluation eﬀorts for the diﬀerent chunking strategies that we have\n",
       "considered.</span> <span style=\"color: cyan;\">We used the prompt template in ﬁgure 4.</span> <span style=\"color: white;\">Begin with True or False.</span> <span style=\"color: red;\">Are the two following answers (Answ er 1 and\n",
       "Answer 2) the same with respect to the question between single e quotes\n",
       "’{question}’?</span> <span style=\"color: green;\">Answer 1: ’{ground_truth_answer}’\n",
       "Answer 2: ’{generated_answer}’\n",
       "Fig.4.Evaluation prompt template.</span> <span style=\"color: yellow;\">The {question },{groundtruthanswer}and\n",
       "{generated answer}ﬁelds are substituted for each question accordingly.</span> <span style=\"color: blue;\">Results in table 5 show that element-based chunking strategies oﬀe r the best\n",
       "question-answering accuracy, which is consistent with page retrie val and para-\n",
       "graph retrieval accuracy.</span> <span style=\"color: magenta;\">Lastly, our approach stands out for its eﬃciency.</span> <span style=\"color: cyan;\">Not only is element t-based\n",
       "chunking generalizable without the need to select the chunk size, bu t when com-\n",
       "pared to the aggregation results that yield the highest retrieval s cores.</span> <span style=\"color: white;\">Element-\n",
       "based chunking achieves the highest retrieval scores with only half the number\n",
       "of chunks required compared to methods that do not consider the structure of\n",
       "the documents (62,529 v.s.</span> <span style=\"color: red;\">112,155).</span> <span style=\"color: green;\">This can reduce the indexing c ost and im-\n",
       "prove query latency because there are only half as many vectors t o index for the\n",
       "vectordb that stores the chunks.</span> <span style=\"color: yellow;\">This underscores the eﬀectiv eness of our solu-\n",
       "tion in optimizing the balance between performance and computation al resource\n",
       "requirements.</span> <span style=\"color: blue;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 11\n",
       "Table 4.</span> <span style=\"color: magenta;\">Retrieval results.</span> <span style=\"color: cyan;\">For each chunking strategy, we show the n umber of chunks\n",
       "for all the documents (Total Chunks), Page Accuracy, and ROU GE and BLEU scores.</span> <span style=\"color: white;\">ROGUE and BLEU are calculated as the maximum score from the li st of recovered\n",
       "contexts for a question when compared to the known evidence f or that question.</span> <span style=\"color: red;\">Chunking strategy Total Chunks Page Accuracy ROGUE BLEU\n",
       "Base 128 64,058 72.34 0.3830.181\n",
       "Base 256 32,051 73.05 0.4330.231\n",
       "Base 512 16,046 68.09 0.4550.250\n",
       "Base Aggregation 112,155 83.69 0.5360.277\n",
       "Keywords Chipper 20,843 46.10 0.4440.315\n",
       "Summary Chipper 20,843 62.41 0.4730.350\n",
       "Preﬁx & Table Description Chipper 20,843 67.38 0.5140.400\n",
       "Chipper Aggregation 62,529 84.40 0.5680.452\n",
       "Table 5.</span> <span style=\"color: green;\">Q&A results.</span> <span style=\"color: yellow;\">We show the percentage of questions with no answ er and as\n",
       "well the accuracy either estimated automatically using GPT -4 or manually.</span> <span style=\"color: blue;\">Chunking strategy No answer GPT-4Manual\n",
       "Base 128 35.46 29.0835.46\n",
       "Base 256 25.53 32.6236.88\n",
       "Base 512 24.82 41.8448.23\n",
       "Keywords Chipper 22.70 43.9753.19\n",
       "Summary Chipper 17.73 43.9751.77\n",
       "Preﬁx & Table Description Chipper 20.57 41.1353.19\n",
       "5 Discussion\n",
       "Results demonstrate the eﬃcacy of our approach in utilizing struct ural elements\n",
       "for chunking, which has enabled us to attain state-of-the-art pe rformance on\n",
       "Q&A tasks within the FinanceBench dataset (accuracy of 50% vs 53 .19%) when\n",
       "an index is createdfromdocument chunksand used forgeneration .Thismethod,\n",
       "which we refer to as element base chunking , has shown to yield consistent results\n",
       "between retrieval and Q&A accuracy.</span> <span style=\"color: magenta;\">We have observed that using basic 512 chunking strategies produc es results\n",
       "most similar to the Unstructured element-based approach, which m ay be due\n",
       "to the fact that 512 tokens share a similar length with the token size within\n",
       "our element-based chunks and capture a long context, but fail ke ep a coherent\n",
       "context in some cases, leaving out relevant information required fo r Q&A.</span> <span style=\"color: cyan;\">This\n",
       "is further observed when considering the ROGUE and BLEU scores in table 4,\n",
       "where the chunk contexts for the baseline have lower scores.</span> <span style=\"color: white;\">These ﬁndings support existing research stating that the best ba sic chunk\n",
       "size varies from data to data [3].</span> <span style=\"color: red;\">These results show, as well, that ou r method\n",
       "adapts to diﬀerent documents without tuning.</span> <span style=\"color: green;\">Our method relies on the struc- 12 Jimeno Yepes et al.</span> <span style=\"color: yellow;\">tural information that is present in the document’s layout to adjus t the chunk\n",
       "size automatically.</span> <span style=\"color: blue;\">We have evaluated aggregating the output of diﬀerent chunking me thods in\n",
       "the retrieval experiments as sown in table 4.</span> <span style=\"color: magenta;\">Even though the aggr egationseems\n",
       "to be eﬀective for retrieval, the Q&A exceeded the GPT-4 token limit , which\n",
       "resulted in a non-eﬀective Q&A solution using the selected model.</span> <span style=\"color: cyan;\">As well, we evaluated variations of the prompt used to generate the answers\n",
       "(see ﬁgure 3).</span> <span style=\"color: white;\">Re-ordering the retrieval context and the quest ion, but results\n",
       "were not statistically diﬀerent.</span> <span style=\"color: red;\">We experimented as well with variatio ns of the\n",
       "verbs using in the prompt, e.g.</span> <span style=\"color: green;\">changing referencing withusing, which seemed to\n",
       "lower the quality of the answers generated.</span> <span style=\"color: yellow;\">This shows that promp t engineering\n",
       "is a relevant factor in RAG.</span> <span style=\"color: blue;\">We evaluated using GPT-4 for evaluation instead of relying on manual evalu-\n",
       "ation.Inmostcases,GPT-4evaluatedcorrectlybut failedwhenam oreelaborate\n",
       "answerisprovided.As shown in ﬁgure5, the answeris 39.7%while the e stimated\n",
       "answer is 39.73% but with a detailed explanation of the calculation.</span> <span style=\"color: magenta;\">Question: ’What is Coca Cola’s FY2021 COGS % margin?</span> <span style=\"color: cyan;\">Calcula te what\n",
       "was asked by utilizing the line items clearly shown in the inc ome\n",
       "statement.’?</span> <span style=\"color: white;\">Answer 1: ’39.7%’\n",
       "Answer 2: ’From the income statement referenced on page 60 of\n",
       "COCACOLA_2021_10K_embedded.json, we can see that Coca Col a’s total\n",
       "revenue in FY2021 was $38,655 million and their cost of goods sold\n",
       "(COGS) was $15,357 million.</span> <span style=\"color: red;\">To calculate the COGS % margin, w e divide\n",
       "the COGS by the total revenue and multiply by 100:\n",
       "(15,357 / 38,655) * 100 = 39.73%\n",
       "So, Coca Cola’s FY2021 COGS % margin was approximately 39.73 %.’\n",
       "Fig.5.Evaluation prompt template\n",
       "6 Conclusions and Future Work\n",
       "Resultsshowthatourelementbasedchunkingstrategyimprovest hestate-of-the-\n",
       "art Q&A for the task, which is achieved by providing a better chunkin g strategy\n",
       "for the processed documents.</span> <span style=\"color: green;\">We provide comparison with baseline chunking\n",
       "strategies that allow us to draw conclusions about diﬀerent chunkin g methods.</span> <span style=\"color: yellow;\">As future work, we would like to perform a similar evaluation in other do -\n",
       "mains, e.g.</span> <span style=\"color: blue;\">biomedical, to understand how our ﬁndings apply outside ﬁ nancial\n",
       "reporting.As well,wewouldlikestudying whichadditionalelementtype s and/or\n",
       "relation between elements would support better chunking strateg ies for RAG.</span> <span style=\"color: magenta;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 13\n",
       "Furthermore, we would like to study the impact of RAG conﬁguration and ele-\n",
       "meant type based chunking.</span> <span style=\"color: cyan;\">References\n",
       "1.</span> <span style=\"color: white;\">Anantha, R., Bethi, T., Vodianik, D., Chappidi, S.: Conte xt Tuning for Retrieval\n",
       "Augmented Generation (2023)\n",
       "2.</span> <span style=\"color: red;\">Balaguer, A., Benara, V., de Freitas Cunha, R.L., de M. Est ev˜ ao Filho, R., Hendry,\n",
       "T., Holstein, D., Marsman, J., Mecklenburg, N., Malvar, S., Nunes, L.O., Padilha,\n",
       "R., Sharp, M., Silva, B., Sharma, S., Aski, V., Chandra, R.: R ag vs ﬁne-tuning:\n",
       "Pipelines, tradeoﬀs, and a case study on agriculture (2024)\n",
       "3.</span> <span style=\"color: green;\">Barnett, S., Kurniawan, S., Thudumu, S., Brannelly, Z., A bdelrazek, M.: Seven\n",
       "Failure Points When Engineering a Retrieval Augmented Gene ration System\n",
       "(2024)\n",
       "4.</span> <span style=\"color: yellow;\">Bentabet,N.I.,Judge, R.,ElMaarouf, I.,Mouilleron, V., Valsamou-Stanislawski, D.,\n",
       "El-Haj, M.: The ﬁnancial document structure extraction sha red task (ﬁntoc 2020).</span> <span style=\"color: blue;\">In: Proceedings of the 1st Joint Workshop on Financial Narra tive Processing and\n",
       "MultiLing Financial Summarisation.</span> <span style=\"color: magenta;\">pp.</span> <span style=\"color: cyan;\">13–22 (2020)\n",
       "5.</span> <span style=\"color: white;\">Chen, H., Jiao, F., Li, X., Qin, C., Ravaut, M., Zhao, R., Xi ong, C., Joty, S.: Chat-\n",
       "GPT’s One-year Anniversary: Are Open-Source Large Language e Models Catching\n",
       "up?</span> <span style=\"color: red;\">arXiv preprint arXiv:2311.16989 (2023)\n",
       "6.</span> <span style=\"color: green;\">Chen, Z., Chen, W., Smiley, C., Shah, S., Borova, I., Langd on, D., Moussa, R.,\n",
       "Beane, M., Huang, T.H., Routledge, B., et al.</span> <span style=\"color: yellow;\">: Finqa: A data et of numerical\n",
       "reasoning over ﬁnancial data.</span> <span style=\"color: blue;\">arXiv preprint arXiv:2109.0 0122 (2021)\n",
       "7.</span> <span style=\"color: magenta;\">Chen, Z., Li, S., Smiley, C., Ma, Z., Shah, S., Wang, W.Y.</span> <span style=\"color: cyan;\">: C onvFinQA: Exploring\n",
       "the Chain of Numerical Reasoning in Conversational Finance Question Answering\n",
       "(2022)\n",
       "8.</span> <span style=\"color: white;\">Choi, S., Gazeley, W., Wong, S.H., Li, T.: Conversational Financial Information\n",
       "Retrieval Model (ConFIRM).</span> <span style=\"color: red;\">arXiv preprint arXiv:2310.130 01 (2023)\n",
       "9.</span> <span style=\"color: green;\">DeSola, V., Hanna, K., Nonis, P.: Finbert: pre-trained mo del on sec ﬁlings for\n",
       "ﬁnancial natural language tasks.</span> <span style=\"color: yellow;\">University of California (2019)\n",
       "10.</span> <span style=\"color: blue;\">El-Haj, M., Rayson, P., Young, S., Walker, M.: Detecting document structure in a\n",
       "very large corpus of UK ﬁnancial reports.</span> <span style=\"color: magenta;\">European Language Resources Associa-\n",
       "tion (ELRA) (2014)\n",
       "11.</span> <span style=\"color: cyan;\">El Maarouf, I., Kang, J., Azzi, A.A., Bellato, S., Gan, M. , El-Haj, M.: The ﬁnancial\n",
       "document structure extraction shared task (FinTOC2021).</span> <span style=\"color: white;\">I n: Proceedings of the\n",
       "3rd Financial Narrative Processing Workshop.</span> <span style=\"color: red;\">pp.</span> <span style=\"color: green;\">111–119 ( 2021)\n",
       "12.</span> <span style=\"color: yellow;\">Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y ., Sun, J., Wang,\n",
       "H.: Retrieval-augmented generation for large language mod els: A survey.</span> <span style=\"color: blue;\">arXiv\n",
       "preprint arXiv:2312.10997 (2023)\n",
       "13.</span> <span style=\"color: magenta;\">Hada, R., Gumma, V., de Wynter, A., Diddee, H., Ahmed, M., Choudhury, M.,\n",
       "Bali, K., Sitaram, S.: Are large language model-based evalu ators the solution to\n",
       "scaling up multilingual evaluation?</span> <span style=\"color: cyan;\">arXiv preprint arXiv: 2309.07462 (2023)\n",
       "14.</span> <span style=\"color: white;\">Islam, P., Kannappan, A., Kiela, D., Qian, R., Scherrer, N., Vidgen, B.: Fi-\n",
       "nanceBench: A New Benchmark for Financial Question Answeri ng.</span> <span style=\"color: red;\">arXiv preprint\n",
       "arXiv:2311.11944 (2023)\n",
       "15.</span> <span style=\"color: green;\">Ji, Z., Lee, N., Frieske,R., Yu,T., Su,D.,Xu,Y., Ishii, E., Bang, Y.J., Madotto, A.,\n",
       "Fung, P.: Survey of Hallucination in Natural Language Gener ation.</span> <span style=\"color: yellow;\">ACM Comput-\n",
       "ing Surveys 55(12), 1–38 (Mar 2023).</span> <span style=\"color: blue;\">https://doi.org/10.1145/3571730, http://\n",
       "dx.doi.org/10.1145/3571730 14 Jimeno Yepes et al.</span> <span style=\"color: magenta;\">16.</span> <span style=\"color: cyan;\">Jiang, A.Q., Sablayrolles, A., Roux, A., Mensch, A., Save ary, B., Bamford, C.,\n",
       "Chaplot, D.S., de las Casas, D., Hanna, E.B., Bressand, F., L engyel, G., Bour, G.,\n",
       "Lample, G., Lavaud, L.R., Saulnier, L., Lachaux, M.A., Stoc k, P., Subramanian,\n",
       "S., Yang, S., Antoniak, S., Scao, T.L., Gervet, T., Lavril, T ., Wang, T., Lacroix,\n",
       "T., Sayed, W.E.</span> <span style=\"color: white;\">: Mixtral of Experts (2024)\n",
       "17.</span> <span style=\"color: red;\">Judge, R., Bentabet, I., Ferradans, S.: The ﬁntoc-2019 sh ared task: Financial doc-\n",
       "ument structure extraction.</span> <span style=\"color: green;\">In: Proceedings of the Second F inancial Narrative\n",
       "Processing Workshop (FNP 2019).</span> <span style=\"color: yellow;\">pp.</span> <span style=\"color: blue;\">51–57 (2019)\n",
       "18.</span> <span style=\"color: magenta;\">Kaddour, J., Harris, J., Mozes, M., Bradley, H., Railean u, R., McHardy, R.: Chal-\n",
       "lenges and applications of large language models.</span> <span style=\"color: cyan;\">arXiv pre print arXiv:2307.10169\n",
       "(2023)\n",
       "19.</span> <span style=\"color: white;\">Kaur, S., Smiley, C., Gupta, A., Sain, J., Wang, D., Sidda gangappa, S.,\n",
       "Aguda, T., Shah, S.: REFinD: Relation Extraction Financial Dataset.</span> <span style=\"color: red;\">In:\n",
       "Proceedings of the 46th International ACM SIGIR Conference on Re-\n",
       "search and Development in Information Retrieval.</span> <span style=\"color: green;\">SIGIR ’23 , ACM (Jul\n",
       "2023).</span> <span style=\"color: yellow;\">https://doi.org/10.1145/3539618.3591911, http://dx.doi.org/10.1145/\n",
       "3539618.3591911\n",
       "20.</span> <span style=\"color: blue;\">Kim, G., Hong, T., Yim, M., Park, J., Yim, J., Hwang, W., Yu n, S., Han, D.,\n",
       "Park, S.: Donut: Document understanding transformer with ut ocr.</span> <span style=\"color: magenta;\">arXiv preprint\n",
       "arXiv:2111.15664 7, 15 (2021)\n",
       "21.</span> <span style=\"color: cyan;\">Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin , V., Goyal, N., K¨ uttler,\n",
       "H., Lewis, M., Yih, W.t., Rockt¨ aschel, T., et al.</span> <span style=\"color: white;\">: Retrieva l-augmented generation\n",
       "for knowledge-intensive NLP tasks.</span> <span style=\"color: red;\">Advances in Neural Info rmation Processing\n",
       "Systems 33, 9459–9474 (2020)\n",
       "22.</span> <span style=\"color: green;\">Li, D., Shao, R., Xie, A., Sheng, Y., Zheng, L., Gonzalez, J.E., Stoica, I., Ma, X.,\n",
       "Zhang, H.: How Long Can Open-Source LLMs Truly Promise on Con text Length?</span> <span style=\"color: yellow;\">(June 2023), https://lmsys.org/blog/2023-06-29-longchat\n",
       "23.</span> <span style=\"color: blue;\">Li, Y., Duan, Y.: The evaluation of experiments of artiﬁc ial general intelligence\n",
       "with gpt-4 based on dikwp.</span> <span style=\"color: magenta;\">arXiv preprint (2023)\n",
       "24.</span> <span style=\"color: cyan;\">Lin, C.Y.</span> <span style=\"color: white;\">: Rogue: A package for automatic evaluation of s ummaries.</span> <span style=\"color: red;\">In: Text sum-\n",
       "marization branches out.</span> <span style=\"color: green;\">pp.</span> <span style=\"color: yellow;\">74–81 (2004)\n",
       "25.</span> <span style=\"color: blue;\">Liu, N.F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqu a, M., Petroni, F., Liang,\n",
       "P.: Lost in the middle: How language models use long contexts .</span> <span style=\"color: magenta;\">arXiv preprint\n",
       "arXiv:2307.03172 (2023)\n",
       "26.</span> <span style=\"color: cyan;\">Liu, Z., Huang, D., Huang, K., Li, Z., Zhao, J.: Finbert: A pre-trained ﬁnancial\n",
       "language representation model for ﬁnancial text mining.</span> <span style=\"color: white;\">In : Proceedings of the\n",
       "twenty-ninthinternationalconferenceoninternational j ointconferencesonartiﬁcial\n",
       "intelligence.</span> <span style=\"color: red;\">pp.</span> <span style=\"color: green;\">4513–4519 (2021)\n",
       "27. llmware: Rag Instruct Benchmark Tester.</span> <span style=\"color: yellow;\">https://huggingface.co/datasets/\n",
       "llmware/rag_instruct_benchmark_tester , Accessed: January 15, 2024\n",
       "28.</span> <span style=\"color: blue;\">Malkov, Y.A., Yashunin, D.A.</span> <span style=\"color: magenta;\">: Eﬃcient and robust approx imate nearest neigh-\n",
       "bor search using hierarchical navigable small world graphs .</span> <span style=\"color: cyan;\">IEEE transactions on\n",
       "pattern analysis and machine intelligence 42(4), 824–836 (2018)\n",
       "29.</span> <span style=\"color: white;\">Moore, S., Nguyen, H.A., Chen, T., Stamper, J.: Assessin g the quality of multiple-\n",
       "choice questions using gpt-4 and rule-based methods.</span> <span style=\"color: red;\">In: Eu ropean Conference on\n",
       "Technology Enhanced Learning.</span> <span style=\"color: green;\">pp.</span> <span style=\"color: yellow;\">229–245.</span> <span style=\"color: blue;\">Springer (2023 )\n",
       "30.</span> <span style=\"color: magenta;\">Naismith, B., Mulcaire, P., Burstein, J.: Automated eva luation of written discourse\n",
       "coherence using gpt-4.</span> <span style=\"color: cyan;\">In: Proceedings of the 18th Workshop on Innovative Use of\n",
       "NLP for Building Educational Applications (BEA 2023).</span> <span style=\"color: white;\">pp.</span> <span style=\"color: red;\">3 94–403 (2023)\n",
       "31.</span> <span style=\"color: green;\">OpenAI, :, Achiam, J., Adler, S., Agarwal, S., et al.</span> <span style=\"color: yellow;\">: GPT -4 Technical Report\n",
       "(2023) Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 15\n",
       "32.</span> <span style=\"color: blue;\">Papineni, K., Roukos, S., Ward, T., Zhu, W.J.</span> <span style=\"color: magenta;\">: Bleu: a met hod for automatic\n",
       "evaluation of machine translation.</span> <span style=\"color: cyan;\">In: Proceedings of the 4 0th annual meeting of\n",
       "the Association for Computational Linguistics.</span> <span style=\"color: white;\">pp.</span> <span style=\"color: red;\">311–31 8 (2002)\n",
       "33.</span> <span style=\"color: green;\">Pﬁtzmann, B., Auer, C., Dolﬁ, M., Nassar, A.S., Staar, P. : Doclaynet: A large\n",
       "human-annotated dataset for document-layout segmentatio n. In: Proceedings of\n",
       "the 28th ACM SIGKDD Conference on Knowledge Discovery and Da ta Mining.</span> <span style=\"color: yellow;\">pp.</span> <span style=\"color: blue;\">3743–3751 (2022)\n",
       "34.</span> <span style=\"color: magenta;\">Pinecone: Chunking strategies for llm applications, https://www.pinecone.io/\n",
       "learn/chunking-strategies/\n",
       "35.</span> <span style=\"color: cyan;\">Reimers, N., Gurevych, I.: Sentence-bert: Sentence emb eddings using siamese bert-\n",
       "networks.</span> <span style=\"color: white;\">In: Proceedings of the 2019 Conference on Empiric al Methods in Nat-\n",
       "ural Language Processing.</span> <span style=\"color: red;\">Association for Computational L inguistics (11 2019),\n",
       "https://arxiv.org/abs/1908.10084\n",
       "36.</span> <span style=\"color: green;\">Retteter, J.: Mastering Table Extraction: Revolutioni ze Your Earnings Re-\n",
       "ports Analysis with AI.</span> <span style=\"color: yellow;\">https://medium.com/unstructured-io/mastering-\n",
       "table-extraction-revolutionize-your-earnings-report s-analysis-with-\n",
       "ai-1bc32c22720e , Accessed: January 15, 2024\n",
       "37.</span> <span style=\"color: blue;\">Rizinski, M., Peshov, H., Mishev, K., Jovanovik,M., Tra janov, D.: SentimentAnal-\n",
       "ysis in Finance: From Transformers Back to eXplainable Lexi cons (XLex) (2023)\n",
       "38.</span> <span style=\"color: magenta;\">Shah, R.S., Chawla, K., Eidnani, D., Shah, A., Du, W., Cha va, S., Raman, N.,\n",
       "Smiley, C., Chen, J., Yang, D.: WHEN FLUE MEETS FLANG: Benchm arks and\n",
       "Large Pre-trained Language Model for Financial Domain (202 2)\n",
       "39.</span> <span style=\"color: cyan;\">Singh Phogat, K., Harsha, C., Dasaratha, S., Ramakrishn a, S., Akhil Puranam, S.:\n",
       "Zero-Shot Question Answering over Financial Documents usi ng Large Language\n",
       "Models.</span> <span style=\"color: white;\">arXiv e-prints pp.</span> <span style=\"color: red;\">arXiv–2311 (2023)\n",
       "40.</span> <span style=\"color: green;\">Wu,S.,Irsoy,O.,Lu,S.,Dabravolski,V.,Dredze,M., Ge hrmann,S.,Kambadur,P.,\n",
       "Rosenberg, D., Mann, G.: BloombergGPT: A Large Language Mod el for Finance\n",
       "(2023)\n",
       "41.</span> <span style=\"color: yellow;\">Xu, P., Ping, W., Wu, X., McAfee, L., Zhu, C., Liu, Z., Subr amanian, S., Bakhtu-\n",
       "rina,E.,Shoeybi,M.,Catanzaro, B.:RetrievalmeetsLongC ontextLargeLanguage\n",
       "Models (2023)\n",
       "42.</span> <span style=\"color: blue;\">Yang, H., Liu, X.Y., Wang, C.D.</span> <span style=\"color: magenta;\">: FinGPT: Open-SourceFin ancial Large Language\n",
       "Models (2023)\n",
       "43.</span> <span style=\"color: cyan;\">Ye, H., Liu, T., Zhang, A., Hua, W., Jia, W.: Cognitive Mir age: A Review of\n",
       "Hallucinations in Large Language Models (2023)\n",
       "44.</span> <span style=\"color: white;\">Zhang, B., Yang, H., Liu, X.Y.</span> <span style=\"color: red;\">: Instruct-FinGPT: Financ ial Sentiment Analysis\n",
       "by Instruction Tuning of General-Purpose Large Language Mo dels (2023)\n",
       "45.</span> <span style=\"color: green;\">Zheng, X., Burdick, D., Popa, L., Zhong, X., Wang, N.X.R.</span> <span style=\"color: yellow;\">: Global table extractor\n",
       "(gte): A framework for joint table identiﬁcation and cell st ructure recognition using\n",
       "visual context.</span> <span style=\"color: blue;\">In: Proceedings of the IEEE/CVF winter conf erence on applications\n",
       "of computer vision.</span> <span style=\"color: magenta;\">pp.</span> <span style=\"color: cyan;\">697–706 (2021)\n",
       "46.</span> <span style=\"color: white;\">Zhu, F., Lei, W., Huang, Y., Wang, C., Zhang, S., Lv, J., Fe ng, F., Chua, T.S.</span> <span style=\"color: red;\">:\n",
       "TAT-QA: A question answering benchmark on a hybrid of tabula r and textual\n",
       "content in ﬁnance.</span> <span style=\"color: green;\">arXiv preprint arXiv:2105.07624 (2021)</span> </td>\n",
       "            <td style=\"text-align: left;\"><span style=\"color: red;\">arXiv:2402.05131v1  [cs.CL]  5 Feb 2024Financial Report Chunking for Eﬀective\n",
       "Retrieval Augmented Generation\n",
       "Antonio Jimeno Yepes, Yao You, Jan Milczek, Sebastian Laverde, an d Leah Li\n",
       "Unstructured Technologies\n",
       "Sacramento, CA, USA\n",
       "leah@unstructured.io\n",
       "https://unstructured.io\n",
       "Abstract.</span> <span style=\"color: green;\">Chunking information is a key step in Retrieval Augmented\n",
       "Generation (RAG).</span> <span style=\"color: yellow;\">Current research primarily centers on pa ragraph-\n",
       "level chunking.</span> <span style=\"color: blue;\">This approach treats all texts as equal and n eglects\n",
       "the information contained in the structure of documents.</span> <span style=\"color: magenta;\">We propose\n",
       "an expanded approach to chunk documents by moving beyond mer e\n",
       "paragraph-level chunking to chunk primary by structural el ement com-\n",
       "ponents of documents.</span> <span style=\"color: cyan;\">Dissecting documents into these cons tituent ele-\n",
       "ments creates a new way to chunk documents that yields the bes t chunk\n",
       "size without tuning.</span> <span style=\"color: white;\">We introduce a novel framework that eva luates how\n",
       "chunking based on element types annotated by document under standing\n",
       "models contributes to the overall context and accuracy of th e informa-\n",
       "tion retrieved.</span> <span style=\"color: red;\">We also demonstrate how this approach impac ts RAG\n",
       "assisted Question & Answer task performance.</span> <span style=\"color: green;\">Our research i ncludes a\n",
       "comprehensive analysis of various element types, their rol e in eﬀective\n",
       "information retrieval, and the impact they have on the quali ty of RAG\n",
       "outputs.</span> <span style=\"color: yellow;\">Findings support that element type based chunking largely im-\n",
       "prove RAG results on ﬁnancial reporting.</span> <span style=\"color: blue;\">Through this resea rch, we are\n",
       "also able to answer how to uncover highly accurate RAG.</span> <span style=\"color: magenta;\">Keywords: Retrieval Augmented Generation ·Document Chunking ·\n",
       "Document Pre-Processing ·Financial Domain ·Large Language Models\n",
       "1 Introduction\n",
       "Existing approaches for document understanding use a combination n of methods\n",
       "from the computer vision and natural language processing domains to identify\n",
       "the diﬀerent components in a document.</span> <span style=\"color: cyan;\">In the rapidly evolving lands cape of\n",
       "artiﬁcial intelligence, the capability to eﬀectively process unstruct ured data is\n",
       "becoming increasingly critical.</span> <span style=\"color: white;\">Large Language Models (LLMs) like GPT -4 have\n",
       "revolutionized natural language understanding and generation, a s evidenced by\n",
       "their prompt-based functionalities [31], enabling a wide range of applic ations [5].</span> <span style=\"color: red;\">However,the eﬃcacyofthese models is often constrainedby their relianceon the\n",
       "size and quality of the data they process.</span> <span style=\"color: green;\">A notable limitation is the re stricted\n",
       "contextualwindowofLLMs,whichhamperstheirabilitytofullycompr ehendthe 2 Jimeno Yepes et al.</span> <span style=\"color: yellow;\">contents of extensive documents [25,22,18].</span> <span style=\"color: blue;\">By dissecting large vo lumes of text\n",
       "into smaller, more focused segments, LLMs can process each part with greater\n",
       "precision, ensuring a thorough understanding of each section.</span> <span style=\"color: magenta;\">Th is segmented\n",
       "approach allows for meticulous analysis of unstructured data, ena bling LLMs to\n",
       "construct a more comprehensive and coherent understanding of the entire docu-\n",
       "meant [41].</span> <span style=\"color: cyan;\">There remains a challenge in ensuring factual accuracy an d relevance\n",
       "in the generated responses, especially when dealing with complex or e xtensive\n",
       "information.</span> <span style=\"color: white;\">Recently, Retrieval Augmented Generation (RAG) [21,12] has been devel-\n",
       "oped to address the hallucination problem with LLMs [15,43] when recovering\n",
       "factual information directly from an LLM.</span> <span style=\"color: red;\">In RAG, instead of answe ring a user\n",
       "query directly using an LLM, the user query is used to retrieve docu ments or\n",
       "segments from a corpus and the top retrieved documents or segm ents are used\n",
       "to generate the answer in conjunction with an LLM.</span> <span style=\"color: green;\">In this way, RAG con-\n",
       "straints the answer to the set of retrieved documents.</span> <span style=\"color: yellow;\">RAGs hav e been used as\n",
       "well to answer questions from single documents [14].</span> <span style=\"color: blue;\">The document s are split\n",
       "into smaller parts or chunks, indexed by a retrieval system and rec overed and\n",
       "processed depending on the user information need.</span> <span style=\"color: magenta;\">In a sense, th is processallows\n",
       "answering questions about information in a single document, thus co ntributing\n",
       "to the set of techniques available for document understanding.</span> <span style=\"color: cyan;\">Since documents need to be chunked for RAG processing, this raises the\n",
       "question about what is the best practice to chunk documents for e ﬀective RAG\n",
       "document understanding.</span> <span style=\"color: white;\">There are several dimensions to consid er when decid-\n",
       "ing how to chunk a document, which includes the size of the chunks.</span> <span style=\"color: red;\">The retrieval system in RAG can use traditional retrieval systems using bag-\n",
       "of-words methods or a vector database.</span> <span style=\"color: green;\">If a vector database is used, then an\n",
       "embedding needs to be obtained from each chunk, thus the number of tokens\n",
       "in the chunk is relevant since the neural networks processing the c hunks might\n",
       "have constraints on the number of tokens.</span> <span style=\"color: yellow;\">As well, diﬀerent chunk sizes might\n",
       "have undesirable retrieval results.</span> <span style=\"color: blue;\">Since the most relevant retrie ved chunks need\n",
       "to be processed by an LLM, the number of tokens in retrieved chun ks might\n",
       "have an eﬀect in the generation of the answer [25].</span> <span style=\"color: magenta;\">As we see, chunk ing is re-\n",
       "quired for RAG systems and there are several advantages and dis advantages\n",
       "when considering how to chunk a document.</span> <span style=\"color: cyan;\">In this work, we study speciﬁcally the chunking of U.S. Securities and Ex-\n",
       "change Commission (SEC)1Financial Reports2, including 10-Ks, 10-Qs, and\n",
       "8-Ks.</span> <span style=\"color: white;\">This study plays a critical role in oﬀering insights into the ﬁnanc ial health\n",
       "and operational dynamics of public companies.</span> <span style=\"color: red;\">These documents pr esent unique\n",
       "challenges in terms of document processing and information extract tion as they\n",
       "consist of varying sizes and layouts, and contain a variety of tabula r informa-\n",
       "tion.</span> <span style=\"color: green;\">Previous work has evaluated the processing of these report s with simple\n",
       "chunking strategies (e.g., tokens), but we believe that a more eﬀec tive use of\n",
       "these reports might be achieved by a better pre-processing of th e documents\n",
       "1https://www.sec.gov\n",
       "2https://www.sec.gov/files/cf-frm.pdf Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 3\n",
       "and chunking conﬁguration3[14].</span> <span style=\"color: yellow;\">To the best of our knowledge, this is the ﬁrst\n",
       "systematic study on chunking for document understanding and mo re speciﬁcally\n",
       "for processing ﬁnancial reports.</span> <span style=\"color: blue;\">2 Related work\n",
       "RAG is an innovative method that has emerged to enhance the perfo rmance of\n",
       "LLMs by incorporating external knowledge, thereby boosting the ir capabilities.</span> <span style=\"color: magenta;\">This technique has undergone substantial research, examining va rious conﬁgu-\n",
       "rations and applications.</span> <span style=\"color: cyan;\">Key research includes Gao et al.’s [12] detaile d analysis\n",
       "of RAG conﬁgurations and their role in enhancing Natural Language Processing\n",
       "(NLP) tasks, reducing errors, and improving factual accuracy.</span> <span style=\"color: white;\">Several context\n",
       "retrieval methods are proposed to dynamically retrieve document s to improve\n",
       "the coherence of generated outputs [1].</span> <span style=\"color: red;\">Other research introdu ced advancements\n",
       "in RAG, including reasoning chain storage and optimization strategies for re-\n",
       "trieval, respectively, broadening the scope and eﬃciency of RAG ap plications in\n",
       "LLMs[21].MorerecentworkhascomparedRAGvsLLMﬁne-tuning,a ndidenti-\n",
       "ﬁed that applying both improves the performance of each individual method [2].</span> <span style=\"color: green;\">Chunkinghasbeen identiﬁed asthe keyfactorinthe successofRAG ,improv-\n",
       "ing the relevance of retrieved content by ensuring accurate embe dding of text\n",
       "with minimal noise.</span> <span style=\"color: yellow;\">Various strategies have been developed for text subdivision,\n",
       "each with its unique approach.</span> <span style=\"color: blue;\">They can be summarized as follows: th eﬁxed\n",
       "size strategy divides text into uniform segments, but it often overlooks the\n",
       "underlying textual structure.</span> <span style=\"color: magenta;\">In contrast, the recursive strategy iteratively\n",
       "subdivides text using separators like punctuation marks, allowing it t o adapt\n",
       "more ﬂuidly to the content.</span> <span style=\"color: cyan;\">The contextual strategy takes this a step further\n",
       "by employing NLP techniques such as sentence segmentation to rep resent the\n",
       "meaning in context.</span> <span style=\"color: white;\">Lastly, the hybrid strategy combines diﬀerent approaches,\n",
       "oﬀering greater ﬂexibility in handling diverse text types [34].</span> <span style=\"color: red;\">Howeve r, an area\n",
       "yet to be explored in RAG chunking based on element types (document t struc-\n",
       "ture), which involves analyzing the inherent structure of document ts, such as\n",
       "headings, paragraphs, tables, to guide the chunking process.</span> <span style=\"color: green;\">Alt hough chunk-\n",
       "ing by Markdown and LaTeX comes closer to addressing element type s, it’s not\n",
       "the same in nature as a dedicated approach that directly considers document\n",
       "structure and element types for chunking, which could potentially y ield more\n",
       "contextually relevant chunks.</span> <span style=\"color: yellow;\">Exploring the structure of ﬁnancial reports is an exceptional are a for es-\n",
       "tablishing optimal principles for chunking.</span> <span style=\"color: blue;\">The intricate nature of do cument\n",
       "structures and contents has resulted in most of the work process sing ﬁnancial\n",
       "reports focusing on the identiﬁcation of structural elements.</span> <span style=\"color: magenta;\">Am ong previous\n",
       "work, we ﬁnd El-Haj et al.</span> <span style=\"color: cyan;\">[10] and the FinTOC challenges [17,4,11] th at have\n",
       "worked at the document structure level for UK and French ﬁnanc ial reports.</span> <span style=\"color: white;\">Ad-\n",
       "3https://www.cnbc.com/2023/12/19/gpt-and-other-ai-mo dels-cant-analyze-\n",
       "an-sec-filing-researchers-find.html 4 Jimeno Yepes et al.</span> <span style=\"color: red;\">ditionally, there is recent work that considers U.S. SEC reports, wh ich includes\n",
       "DocLayNet [33] and more speciﬁcally with the report tables in FinTabN et [45].</span> <span style=\"color: green;\">On the side of ﬁnancial models, there is work in sentiment analysis in ﬁ-\n",
       "nance [37], which includes the pre-training of specialised models such a s Fin-\n",
       "BERT by Liu et al.</span> <span style=\"color: yellow;\">[26], which is a BERT based model pre-trained on large\n",
       "corpora including large collections of ﬁnancial news collected from diﬀ erent sites\n",
       "and FinBERT by DeSola et al, [9] trained on Wikipedia, BookCorpus and U .S.</span> <span style=\"color: blue;\">SEC data.</span> <span style=\"color: magenta;\">Additional models include BloombergGPT [40], FinGPT [42] and\n",
       "Instruct-FinGPT[44].</span> <span style=\"color: cyan;\">MoreadvancedatasetsintheﬁnancialdomainincludeFinQA[6],LLMWa re[27],\n",
       "ConFIRM [8] and TAT-QA [46] among others [7,38,19] that have been p repared\n",
       "for retrieval and or Questions and Answering (Q&A) tasks over sn ippets of ﬁ-\n",
       "nancial data that includes tabular data, which has allowed methods o n large\n",
       "language models to be tested on them [39].</span> <span style=\"color: white;\">Most of the previous work has focused on understanding the layout t of ﬁ-\n",
       "nancial documents or understanding speciﬁc snippets of existing r eports with\n",
       "diﬀerent levels of complexity, but there has not been much researc h in under-\n",
       "standingﬁnancialreportdocuments,exceptsomemorerecentw orkthatincludes\n",
       "FinanceBench [14], in which a set of questions about the content of ﬁ nancial re-\n",
       "ports are proposed that includes the evidence snippet.</span> <span style=\"color: red;\">More speciﬁcally on document chunking methods for RAG, there are stan-\n",
       "dard approaches being considered such as chunking text into span s of a given\n",
       "token length (e.g.</span> <span style=\"color: green;\">128 and 256) or chunking based on sentences.</span> <span style=\"color: yellow;\">O pen source\n",
       "projects already allow simple processing of documents (e.g.</span> <span style=\"color: blue;\">Unstru ctured4, Lla-\n",
       "maindex5or Langchain6), without explicitly considering the table structure on\n",
       "which these chunking strategies are applied.</span> <span style=\"color: magenta;\">Even though diﬀerent approaches are available, an exhaustive eva luation of\n",
       "chunking applied to RAG and speciﬁcally to ﬁnancial reporting, excep t for some\n",
       "limited chunking analysis [14,36], is non-existent.</span> <span style=\"color: cyan;\">In our work, we comp are a\n",
       "broad range of chunking approachesin addition to more simple ones a nd provide\n",
       "an analysis of the outcomes of diﬀerent methods when asking quest ions about\n",
       "diﬀerent aspects of the reports.</span> <span style=\"color: white;\">3 Methods\n",
       "In this section, wepresentthe chunkingstrategiesthat we havee valuated.</span> <span style=\"color: red;\">Before\n",
       "describing the chunking strategies, we present the RAG environme nt in which\n",
       "these strategies have been evaluated and the dataset used for e valuation.</span> <span style=\"color: green;\">3.1 RAG setting for the experiments\n",
       "The RAG pipeline used to process a user question is presented in ﬁgur e 1 and is\n",
       "a common instance ofa RAG [12].</span> <span style=\"color: yellow;\">Priorto answeringany question abo ut a given\n",
       "4https://unstructured.io\n",
       "5https://www.llamaindex.ai\n",
       "6https://www.langchain.com Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 5\n",
       "document, the document is split into chunks and the chunks are inde xed into\n",
       "a vector database (vectordb).</span> <span style=\"color: blue;\">When a question is sent to the RAG system, the\n",
       "top-k chunks most similar to the question are retrieved from the ve ctor database\n",
       "and used to generate the answer using a large language model as ge nerator.</span> <span style=\"color: magenta;\">In\n",
       "order to retrieve chunks from the vector database, the questio n is encoded into a\n",
       "vector that is compared to the vector previously generated from the chunks.</span> <span style=\"color: cyan;\">To\n",
       "prompt the generator, the question is converted into a set of inst ructions that\n",
       "instruct the LLM to ﬁnd the answer within the top-k retrieved chun ks.</span> <span style=\"color: white;\">Fig.1.RAG steps to answer a question about a document\n",
       "In our experiments, we modify the way documents are chunked prior to\n",
       "being indexed in the vector database.</span> <span style=\"color: red;\">All other settings remain con stant.</span> <span style=\"color: green;\">In the\n",
       "following sections, we describe in more detail each one of the compon ents and\n",
       "processes used.</span> <span style=\"color: yellow;\">3.2 Indexing and retrieval\n",
       "We have used the open source system Weaviate7as our vector database.</span> <span style=\"color: blue;\">As\n",
       "encoder model, we have used a sentence transformer [35] trained on over 256M\n",
       "questions and answers, which is available from the HuggingFace syst em8.</span> <span style=\"color: magenta;\">As shown in ﬁgure 2, to index a document, ﬁrst the document is split in to\n",
       "chunks, then each chunk is processed by an encoder model and th en indexed into\n",
       "the vector database.</span> <span style=\"color: cyan;\">Based on the chunking strategy a document t will be split\n",
       "into a larger or smaller set of chunks.</span> <span style=\"color: white;\">Fig.2.Indexing of document chunks into the vector database\n",
       "7https://weaviate.io/developers/weaviate\n",
       "8https://huggingface.co/sentence-transformers/multi- qa-mpnet-base-dot-\n",
       "v1 6 Jimeno Yepes et al.</span> <span style=\"color: red;\">As shown in ﬁgure 1, to retrievechunks relevant to a question, the question is\n",
       "converted into a vector representation and the vector database e returns a ranked\n",
       "list of chunks based on the similarity between question vector and th e chunks\n",
       "in the database.</span> <span style=\"color: green;\">Weaviate implements an approximate nearest neigh bours algo-\n",
       "rhythm [28] as their retrieval approach, which supports fast retrie val with high\n",
       "accuracy.</span> <span style=\"color: yellow;\">In our experiments, we retrieve the top-10 chunks fo r each question.</span> <span style=\"color: blue;\">3.3 Generation\n",
       "Once the vector database has retrieved the top-10 chunks base d on a question,\n",
       "the generation module generates the answer.</span> <span style=\"color: magenta;\">To do so, a prompt b ased on the\n",
       "question and the retrieved chunks are provided to a large language model that\n",
       "generates the answer of the system.</span> <span style=\"color: cyan;\">WehaveusedGPT-4[31]asthegenerator,whichhasshownbestpe rformance\n",
       "compared to earlier versions.</span> <span style=\"color: white;\">As well, its performance was better c ompared to\n",
       "existing open source alternatives [22] such as Mixtral [16].</span> <span style=\"color: red;\">We used t he prompt\n",
       "presented in ﬁgure 3 that we designed on another similar RAG implement tation\n",
       "with diﬀerent document types.</span> <span style=\"color: green;\">The prompt conditions the answer t o the query\n",
       "and the chunks, referred to as source, and if the generator cannot answer it\n",
       "should return No answer .</span> <span style=\"color: yellow;\">please answer the question below by referencing the list of s ources\n",
       "provided after the question; if the question can not be answe red just\n",
       "respond ’No answer’.</span> <span style=\"color: blue;\">The sources are listed after \"Sources: \".</span> <span style=\"color: magenta;\">Question: {query}\n",
       "Sources: {key} - {source}\n",
       "...\n",
       "Fig.3.Example prompt template used by the generator\n",
       "3.4 Chunking\n",
       "As a baseline chunking method, we have split the documents into chun ks of size\n",
       "ntokens (n∈ {128,256,512}).</span> <span style=\"color: cyan;\">As well, an aggregation of the output by the\n",
       "indexing of diﬀerent chunking conﬁgurations has been considered.</span> <span style=\"color: white;\">In addition to chunking based on the number of tokens, we have pro cessed\n",
       "the documents using computer vision and natural language process singto extract\n",
       "elements identiﬁed in the reports.</span> <span style=\"color: red;\">The list of elements considered ar e provided\n",
       "by the Unstructured9open source library.</span> <span style=\"color: green;\">From the set of processing strategies,\n",
       "9https://unstructured-io.github.io/unstructured/intr oduction.html#\n",
       "elements Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 7\n",
       "we use Chipper, a vision encoder decoder10model inspired by Donut [20] to\n",
       "showcase the performance diﬀerence.</span> <span style=\"color: yellow;\">The Chipper model output s results as a\n",
       "JSON representation of the document, listing elements per page ch aracterized\n",
       "by their element type.</span> <span style=\"color: blue;\">Additionally, Chipper provides a bounding box e nclosing\n",
       "each element on the page and the corresponding element text.</span> <span style=\"color: magenta;\">These elements are sometimes short to be considered as chunks, s o to gen-\n",
       "erate chunks from elements the following steps have been followed.</span> <span style=\"color: cyan;\">Given the\n",
       "structureofﬁnancereportingdocuments,ourstructuralchu nkingeﬀortsarecon-\n",
       "centrated on processing titles, texts, and tables.</span> <span style=\"color: white;\">The steps to g enerate element-\n",
       "based chunks are:\n",
       "–if the element text length is smaller than 2,048 characters, a merge w ith the\n",
       "following element is attempted\n",
       "–iteratively, element texts are merged following the step above till eit her the\n",
       "desired length is achieved, without breaking the element\n",
       "–if a title element is found, a new chunk is started\n",
       "–if a table element is found, a new chunk is started, preservingthe en tire table\n",
       "After element-based chunks have been derived, three types of m etadata are\n",
       "generated to enrich the content and support eﬃcient indexing.</span> <span style=\"color: red;\">Th e ﬁrst two\n",
       "types, generated via predeﬁned prompt templates with GPT-4, inc lude: 1) up to\n",
       "6 representative keywords of the composite chunk 2) a summarise d paragraph\n",
       "of the composite chunk.</span> <span style=\"color: green;\">The third type is 3) Naive representation u sing the ﬁrst\n",
       "two sentences from a composite chunk (a kind of preﬁx) and in the c ase oftables,\n",
       "the description of the table, which is typically identiﬁed in the table cap tion.</span> <span style=\"color: yellow;\">3.5 Dataset\n",
       "To evaluate the performance of the diﬀerent chunking approache s, we have used\n",
       "the FinanceBenchdataset [14].</span> <span style=\"color: blue;\">FinanceBench is anew benchmarking datasetde-\n",
       "signed to assess the capabilities of LLMs in answering open-book ﬁna ncial ques-\n",
       "tions.</span> <span style=\"color: magenta;\">The questions collected are realistic and applicable to real-wor ld ﬁnancial\n",
       "scenarios and include complex questions that require computationa l reasoning\n",
       "to arrive at conclusive answers.</span> <span style=\"color: cyan;\">This dataset is made of 150 instances with questions and answers fr om 84\n",
       "unique reports.</span> <span style=\"color: white;\">The dataset does not include the source document ts, which we\n",
       "have downloaded.</span> <span style=\"color: red;\">We were able to recover only 80 documents, which reduces\n",
       "the number of questions to 141 from the original 150.</span> <span style=\"color: green;\">The distribut ion of Un-\n",
       "structured elements predictions are shown in table 1.</span> <span style=\"color: yellow;\">Documents have a varying number of pages, spanning from 4 pages (FOOT-\n",
       "LOCKER 20228Kdated-2022-05-20) to 549 pages (e.g.</span> <span style=\"color: blue;\">PEPSICO 202110K),\n",
       "with an average of 147.34 with std 97.78 with a total of 11,787 pages c ombined.</span> <span style=\"color: magenta;\">Each instance contains a link to the report, the question, a questio n type , the\n",
       "answerand supportingevidence,with pagenumberwherethe evide nce islocated\n",
       "10https://huggingface.co/docs/transformers/model_doc/ vision-encoder-\n",
       "decoder 8 Jimeno Yepes et al.</span> <span style=\"color: cyan;\">Table 1.</span> <span style=\"color: white;\">Unstructured element types distribution for Chipper predictions against doc-\n",
       "uments in FinanceBench.</span> <span style=\"color: red;\">Element Type Chipper Entities\n",
       "NarrativeText 61,780\n",
       "Title 29,664\n",
       "ListItem 33,054\n",
       "UncategorizedText 9,400\n",
       "Footer 1,026\n",
       "Table 7,700\n",
       "Header 3,959\n",
       "Image 26\n",
       "FigureCaption 54\n",
       "Formula 29\n",
       "Address 229\n",
       "Total 146,921\n",
       "in the document, that allows for a closer evaluation of the results.</span> <span style=\"color: green;\">B ased on the\n",
       "page number, evidence contexts are located in diﬀerent areas in th e documents,\n",
       "ranging from the ﬁrst page in some cases up to page 304 in one instan ce.</span> <span style=\"color: yellow;\">The\n",
       "mean page number to ﬁnd the evidence is 54.58 with a standard deviat ion of\n",
       "43.66, which shows that evidence contexts to answer the question s are spread\n",
       "within a document.</span> <span style=\"color: blue;\">These characteristics make FinanceBench a per fect dataset\n",
       "for evaluating RAG.</span> <span style=\"color: magenta;\">An example instance is available in table 2.</span> <span style=\"color: cyan;\">4 Results\n",
       "Inthissection,weevaluatethediﬀerentchunkingstrategiesusing theFinanceBench\n",
       "dataset.</span> <span style=\"color: white;\">Our evaluation is grounded in factual accuracy, which allow ws us to mea-\n",
       "sure the eﬀectiveness of each conﬁguration by its precision in retr ieving answers\n",
       "that match the ground truth, as well as its generation abilities.</span> <span style=\"color: red;\">We are considering 80 documents and 141 questions from FinanceBe nch.</span> <span style=\"color: green;\">Using the OpenAI tokenizer from the model text-embedding-ada-002 that uses\n",
       "the tokenizer cl100kbase11, there are on average 102,444.35 tokens with std of\n",
       "61,979.45, which shows the large variability of document lengths as se en by the\n",
       "diﬀerent number of pages per document presented above.</span> <span style=\"color: yellow;\">Chunking Eﬃciency The ﬁrst thing we analyzed is the total number of\n",
       "chunks, as it impacts indexing time.</span> <span style=\"color: blue;\">We would like to observe the relatio nship\n",
       "between accuracy and total chunk size.</span> <span style=\"color: magenta;\">Table 3 shows the number of chunks\n",
       "derived from each one of the processing methods.</span> <span style=\"color: cyan;\">Unstructured element-based\n",
       "chunks are closer in size to Base 512, and as the chunk size decrease es for the\n",
       "basic chunking strategies, the total number of chunks increases linearly.</span> <span style=\"color: white;\">11https://platform.openai.com/docs/guides/embeddings/ limitations-risks Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 9\n",
       "Table 2.</span> <span style=\"color: red;\">Example question from the FinanceBench dataset\n",
       "Field Value\n",
       "ﬁnancebench idﬁnancebench id00859\n",
       "docname VERIZON 202110K\n",
       "doclink https://www.verizon.com/about/sites/default/ﬁles/20 21-Annual-\n",
       "Report-on-Form-10-K.pdf\n",
       "question type’novel-generated’\n",
       "question Among all of the derivative instruments that Verizon used to manage\n",
       "the exposure to ﬂuctuations of foreign currencies exchange rates or\n",
       "interest rates, which one had the highest notional value in F Y 2021?</span> <span style=\"color: green;\">answer Cross currency swaps.</span> <span style=\"color: yellow;\">Its notional value was $32,502 million.,\n",
       "evidence textDerivative Instruments We enter into derivative transacti owns primarily\n",
       "to manage our exposure to ﬂuctuations in foreign currency ex change\n",
       "rates and interest rates.</span> <span style=\"color: blue;\">We employ risk management strateg ies, which\n",
       "may include the use of a variety of derivatives including int erest rate\n",
       "swaps, cross currency swaps, forward starting interest rat e swaps, trea-\n",
       "sury rate locks, interest rate caps, swaptions and foreign e xchange for-\n",
       "wards.</span> <span style=\"color: magenta;\">We do not hold derivatives for trading purposes.</span> <span style=\"color: cyan;\">The f ollowing\n",
       "table sets forth the notional amounts of our outstanding der ivative in-\n",
       "struments: (dollars in millions) AtDecember 31, 2021 2020 I nterestrate\n",
       "swaps $19,779 $17,768 Cross currency swaps 32,502 26,288 Forward\n",
       "starting interest rate swaps 1,000 2,000 Foreign exchange f orwards 932\n",
       "1,405\n",
       "pagenumber 85\n",
       "Table 3.</span> <span style=\"color: white;\">Chunks statistics for basic chunking elements and Unstruct ured elements\n",
       "Processing total chunks mean chunks per document (std) tables mean (std)\n",
       "Base 128 64,058 800.73 (484.11) N/A\n",
       "Base 256 32,051 400.64 (242.04) N/A\n",
       "Base 512 16,046 200.58 (121.01) N/A\n",
       "Chipper 20,843 260.57 (145.80) 96.20 (57.53)\n",
       "Retrieval Accuracy Secondly, we evaluate the capabilities of each chunking\n",
       "strategy in terms of retrieval accuracy.</span> <span style=\"color: red;\">We use the page number s in the ground\n",
       "truth to calculate the page-level retrieval accuracy, and we use ROGUE [24] and\n",
       "BLEU [32] scores to evaluate the accuracy of paragraph-levelre trieval compared\n",
       "to the ground truth evidence paragraphs.</span> <span style=\"color: green;\">As shown in Table 4, when compared to Unstructured element-base d chunk-\n",
       "ing strategies, basic chunking strategies seem to have higher page -level retrieval\n",
       "accuracy but lower paragraph-level accuracy on average.</span> <span style=\"color: yellow;\">Addit ionally, basic\n",
       "chunking strategies also lack consistency between page-level and paragraph-level\n",
       "accuracy; higher page-level accuracy doesn’t ensure higher par agraph-level ac-\n",
       "curacy.</span> <span style=\"color: blue;\">For example, Base 128 has the second highest page-level accuracy but 10 Jimeno Yepes et al.</span> <span style=\"color: magenta;\">the lowest paragraph-level scores among all.</span> <span style=\"color: cyan;\">On the other hand, e lement-based\n",
       "chunking strategies showed more consistent results.</span> <span style=\"color: white;\">A fascinating discovery is that when various chunking strategies ar e com-\n",
       "bined, it results in enhanced retrieval scores, achieving superior p performance\n",
       "at both the page level (84.4%) and paragraph level (with ROGUE at 0 .568%\n",
       "and BLEU at 0.452%).</span> <span style=\"color: red;\">This ﬁnding addresses an unresolved question : how to\n",
       "improve the accuracy of RAG.</span> <span style=\"color: green;\">The element based method provides the highest scores and it also pr ovides a\n",
       "mechanism to chunk documents without the need to ﬁne tune hyper -parameters\n",
       "like the number of tokens in a chunk.</span> <span style=\"color: yellow;\">This suggests the element base d method\n",
       "is more generalizable and can be applied to new types of documents.</span> <span style=\"color: blue;\">Q&A Accuracy Third, we evaluate the Q&Aaccuracyfor the chunking strate-\n",
       "gies.Inadditiontomanualevaluation,wehaveinvestigatedanauto maticevalua-\n",
       "tionusingGPT-4.GPT-4compareshowtheanswersprovidedbyour methodare\n",
       "similar to or diﬀerent from the FinanceBench gold standard, similar ap proaches\n",
       "have been previously evaluated [13,23,29,30].</span> <span style=\"color: magenta;\">The automatic evaluatio n allows\n",
       "scaling the evaluation eﬀorts for the diﬀerent chunking strategies that we have\n",
       "considered.</span> <span style=\"color: cyan;\">We used the prompt template in ﬁgure 4.</span> <span style=\"color: white;\">Begin with True or False.</span> <span style=\"color: red;\">Are the two following answers (Answ er 1 and\n",
       "Answer 2) the same with respect to the question between single e quotes\n",
       "’{question}’?</span> <span style=\"color: green;\">Answer 1: ’{ground_truth_answer}’\n",
       "Answer 2: ’{generated_answer}’\n",
       "Fig.4.Evaluation prompt template.</span> <span style=\"color: yellow;\">The {question },{groundtruthanswer}and\n",
       "{generated answer}ﬁelds are substituted for each question accordingly.</span> <span style=\"color: blue;\">Results in table 5 show that element-based chunking strategies oﬀe r the best\n",
       "question-answering accuracy, which is consistent with page retrie val and para-\n",
       "graph retrieval accuracy.</span> <span style=\"color: magenta;\">Lastly, our approach stands out for its eﬃciency.</span> <span style=\"color: cyan;\">Not only is element t-based\n",
       "chunking generalizable without the need to select the chunk size, bu t when com-\n",
       "pared to the aggregation results that yield the highest retrieval s cores.</span> <span style=\"color: white;\">Element-\n",
       "based chunking achieves the highest retrieval scores with only half the number\n",
       "of chunks required compared to methods that do not consider the structure of\n",
       "the documents (62,529 v.s.</span> <span style=\"color: red;\">112,155).</span> <span style=\"color: green;\">This can reduce the indexing c ost and im-\n",
       "prove query latency because there are only half as many vectors t o index for the\n",
       "vectordb that stores the chunks.</span> <span style=\"color: yellow;\">This underscores the eﬀectiv eness of our solu-\n",
       "tion in optimizing the balance between performance and computation al resource\n",
       "requirements.</span> <span style=\"color: blue;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 11\n",
       "Table 4.</span> <span style=\"color: magenta;\">Retrieval results.</span> <span style=\"color: cyan;\">For each chunking strategy, we show the n umber of chunks\n",
       "for all the documents (Total Chunks), Page Accuracy, and ROU GE and BLEU scores.</span> <span style=\"color: white;\">ROGUE and BLEU are calculated as the maximum score from the li st of recovered\n",
       "contexts for a question when compared to the known evidence f or that question.</span> <span style=\"color: red;\">Chunking strategy Total Chunks Page Accuracy ROGUE BLEU\n",
       "Base 128 64,058 72.34 0.3830.181\n",
       "Base 256 32,051 73.05 0.4330.231\n",
       "Base 512 16,046 68.09 0.4550.250\n",
       "Base Aggregation 112,155 83.69 0.5360.277\n",
       "Keywords Chipper 20,843 46.10 0.4440.315\n",
       "Summary Chipper 20,843 62.41 0.4730.350\n",
       "Preﬁx & Table Description Chipper 20,843 67.38 0.5140.400\n",
       "Chipper Aggregation 62,529 84.40 0.5680.452\n",
       "Table 5.</span> <span style=\"color: green;\">Q&A results.</span> <span style=\"color: yellow;\">We show the percentage of questions with no answ er and as\n",
       "well the accuracy either estimated automatically using GPT -4 or manually.</span> <span style=\"color: blue;\">Chunking strategy No answer GPT-4Manual\n",
       "Base 128 35.46 29.0835.46\n",
       "Base 256 25.53 32.6236.88\n",
       "Base 512 24.82 41.8448.23\n",
       "Keywords Chipper 22.70 43.9753.19\n",
       "Summary Chipper 17.73 43.9751.77\n",
       "Preﬁx & Table Description Chipper 20.57 41.1353.19\n",
       "5 Discussion\n",
       "Results demonstrate the eﬃcacy of our approach in utilizing struct ural elements\n",
       "for chunking, which has enabled us to attain state-of-the-art pe rformance on\n",
       "Q&A tasks within the FinanceBench dataset (accuracy of 50% vs 53 .19%) when\n",
       "an index is createdfromdocument chunksand used forgeneration .Thismethod,\n",
       "which we refer to as element base chunking , has shown to yield consistent results\n",
       "between retrieval and Q&A accuracy.</span> <span style=\"color: magenta;\">We have observed that using basic 512 chunking strategies produc es results\n",
       "most similar to the Unstructured element-based approach, which m ay be due\n",
       "to the fact that 512 tokens share a similar length with the token size within\n",
       "our element-based chunks and capture a long context, but fail ke ep a coherent\n",
       "context in some cases, leaving out relevant information required fo r Q&A.</span> <span style=\"color: cyan;\">This\n",
       "is further observed when considering the ROGUE and BLEU scores in table 4,\n",
       "where the chunk contexts for the baseline have lower scores.</span> <span style=\"color: white;\">These ﬁndings support existing research stating that the best ba sic chunk\n",
       "size varies from data to data [3].</span> <span style=\"color: red;\">These results show, as well, that ou r method\n",
       "adapts to diﬀerent documents without tuning.</span> <span style=\"color: green;\">Our method relies on the struc- 12 Jimeno Yepes et al.</span> <span style=\"color: yellow;\">tural information that is present in the document’s layout to adjus t the chunk\n",
       "size automatically.</span> <span style=\"color: blue;\">We have evaluated aggregating the output of diﬀerent chunking me thods in\n",
       "the retrieval experiments as sown in table 4.</span> <span style=\"color: magenta;\">Even though the aggr egationseems\n",
       "to be eﬀective for retrieval, the Q&A exceeded the GPT-4 token limit , which\n",
       "resulted in a non-eﬀective Q&A solution using the selected model.</span> <span style=\"color: cyan;\">As well, we evaluated variations of the prompt used to generate the answers\n",
       "(see ﬁgure 3).</span> <span style=\"color: white;\">Re-ordering the retrieval context and the quest ion, but results\n",
       "were not statistically diﬀerent.</span> <span style=\"color: red;\">We experimented as well with variatio ns of the\n",
       "verbs using in the prompt, e.g.</span> <span style=\"color: green;\">changing referencing withusing, which seemed to\n",
       "lower the quality of the answers generated.</span> <span style=\"color: yellow;\">This shows that promp t engineering\n",
       "is a relevant factor in RAG.</span> <span style=\"color: blue;\">We evaluated using GPT-4 for evaluation instead of relying on manual evalu-\n",
       "ation.Inmostcases,GPT-4evaluatedcorrectlybut failedwhenam oreelaborate\n",
       "answerisprovided.As shown in ﬁgure5, the answeris 39.7%while the e stimated\n",
       "answer is 39.73% but with a detailed explanation of the calculation.</span> <span style=\"color: magenta;\">Question: ’What is Coca Cola’s FY2021 COGS % margin?</span> <span style=\"color: cyan;\">Calcula te what\n",
       "was asked by utilizing the line items clearly shown in the inc ome\n",
       "statement.’?</span> <span style=\"color: white;\">Answer 1: ’39.7%’\n",
       "Answer 2: ’From the income statement referenced on page 60 of\n",
       "COCACOLA_2021_10K_embedded.json, we can see that Coca Col a’s total\n",
       "revenue in FY2021 was $38,655 million and their cost of goods sold\n",
       "(COGS) was $15,357 million.</span> <span style=\"color: red;\">To calculate the COGS % margin, w e divide\n",
       "the COGS by the total revenue and multiply by 100:\n",
       "(15,357 / 38,655) * 100 = 39.73%\n",
       "So, Coca Cola’s FY2021 COGS % margin was approximately 39.73 %.’\n",
       "Fig.5.Evaluation prompt template\n",
       "6 Conclusions and Future Work\n",
       "Resultsshowthatourelementbasedchunkingstrategyimprovest hestate-of-the-\n",
       "art Q&A for the task, which is achieved by providing a better chunkin g strategy\n",
       "for the processed documents.</span> <span style=\"color: green;\">We provide comparison with baseline chunking\n",
       "strategies that allow us to draw conclusions about diﬀerent chunkin g methods.</span> <span style=\"color: yellow;\">As future work, we would like to perform a similar evaluation in other do -\n",
       "mains, e.g.</span> <span style=\"color: blue;\">biomedical, to understand how our ﬁndings apply outside ﬁ nancial\n",
       "reporting.As well,wewouldlikestudying whichadditionalelementtype s and/or\n",
       "relation between elements would support better chunking strateg ies for RAG.</span> <span style=\"color: magenta;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 13\n",
       "Furthermore, we would like to study the impact of RAG conﬁguration and ele-\n",
       "meant type based chunking.</span> <span style=\"color: cyan;\">References\n",
       "1.</span> <span style=\"color: white;\">Anantha, R., Bethi, T., Vodianik, D., Chappidi, S.: Conte xt Tuning for Retrieval\n",
       "Augmented Generation (2023)\n",
       "2.</span> <span style=\"color: red;\">Balaguer, A., Benara, V., de Freitas Cunha, R.L., de M. Est ev˜ ao Filho, R., Hendry,\n",
       "T., Holstein, D., Marsman, J., Mecklenburg, N., Malvar, S., Nunes, L.O., Padilha,\n",
       "R., Sharp, M., Silva, B., Sharma, S., Aski, V., Chandra, R.: R ag vs ﬁne-tuning:\n",
       "Pipelines, tradeoﬀs, and a case study on agriculture (2024)\n",
       "3.</span> <span style=\"color: green;\">Barnett, S., Kurniawan, S., Thudumu, S., Brannelly, Z., A bdelrazek, M.: Seven\n",
       "Failure Points When Engineering a Retrieval Augmented Gene ration System\n",
       "(2024)\n",
       "4.</span> <span style=\"color: yellow;\">Bentabet,N.I.,Judge, R.,ElMaarouf, I.,Mouilleron, V., Valsamou-Stanislawski, D.,\n",
       "El-Haj, M.: The ﬁnancial document structure extraction sha red task (ﬁntoc 2020).</span> <span style=\"color: blue;\">In: Proceedings of the 1st Joint Workshop on Financial Narra tive Processing and\n",
       "MultiLing Financial Summarisation.</span> <span style=\"color: magenta;\">pp.</span> <span style=\"color: cyan;\">13–22 (2020)\n",
       "5.</span> <span style=\"color: white;\">Chen, H., Jiao, F., Li, X., Qin, C., Ravaut, M., Zhao, R., Xi ong, C., Joty, S.: Chat-\n",
       "GPT’s One-year Anniversary: Are Open-Source Large Language e Models Catching\n",
       "up?</span> <span style=\"color: red;\">arXiv preprint arXiv:2311.16989 (2023)\n",
       "6.</span> <span style=\"color: green;\">Chen, Z., Chen, W., Smiley, C., Shah, S., Borova, I., Langd on, D., Moussa, R.,\n",
       "Beane, M., Huang, T.H., Routledge, B., et al.</span> <span style=\"color: yellow;\">: Finqa: A data et of numerical\n",
       "reasoning over ﬁnancial data.</span> <span style=\"color: blue;\">arXiv preprint arXiv:2109.0 0122 (2021)\n",
       "7.</span> <span style=\"color: magenta;\">Chen, Z., Li, S., Smiley, C., Ma, Z., Shah, S., Wang, W.Y.</span> <span style=\"color: cyan;\">: C onvFinQA: Exploring\n",
       "the Chain of Numerical Reasoning in Conversational Finance Question Answering\n",
       "(2022)\n",
       "8.</span> <span style=\"color: white;\">Choi, S., Gazeley, W., Wong, S.H., Li, T.: Conversational Financial Information\n",
       "Retrieval Model (ConFIRM).</span> <span style=\"color: red;\">arXiv preprint arXiv:2310.130 01 (2023)\n",
       "9.</span> <span style=\"color: green;\">DeSola, V., Hanna, K., Nonis, P.: Finbert: pre-trained mo del on sec ﬁlings for\n",
       "ﬁnancial natural language tasks.</span> <span style=\"color: yellow;\">University of California (2019)\n",
       "10.</span> <span style=\"color: blue;\">El-Haj, M., Rayson, P., Young, S., Walker, M.: Detecting document structure in a\n",
       "very large corpus of UK ﬁnancial reports.</span> <span style=\"color: magenta;\">European Language Resources Associa-\n",
       "tion (ELRA) (2014)\n",
       "11.</span> <span style=\"color: cyan;\">El Maarouf, I., Kang, J., Azzi, A.A., Bellato, S., Gan, M. , El-Haj, M.: The ﬁnancial\n",
       "document structure extraction shared task (FinTOC2021).</span> <span style=\"color: white;\">I n: Proceedings of the\n",
       "3rd Financial Narrative Processing Workshop.</span> <span style=\"color: red;\">pp.</span> <span style=\"color: green;\">111–119 ( 2021)\n",
       "12.</span> <span style=\"color: yellow;\">Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y ., Sun, J., Wang,\n",
       "H.: Retrieval-augmented generation for large language mod els: A survey.</span> <span style=\"color: blue;\">arXiv\n",
       "preprint arXiv:2312.10997 (2023)\n",
       "13.</span> <span style=\"color: magenta;\">Hada, R., Gumma, V., de Wynter, A., Diddee, H., Ahmed, M., Choudhury, M.,\n",
       "Bali, K., Sitaram, S.: Are large language model-based evalu ators the solution to\n",
       "scaling up multilingual evaluation?</span> <span style=\"color: cyan;\">arXiv preprint arXiv: 2309.07462 (2023)\n",
       "14.</span> <span style=\"color: white;\">Islam, P., Kannappan, A., Kiela, D., Qian, R., Scherrer, N., Vidgen, B.: Fi-\n",
       "nanceBench: A New Benchmark for Financial Question Answeri ng.</span> <span style=\"color: red;\">arXiv preprint\n",
       "arXiv:2311.11944 (2023)\n",
       "15.</span> <span style=\"color: green;\">Ji, Z., Lee, N., Frieske,R., Yu,T., Su,D.,Xu,Y., Ishii, E., Bang, Y.J., Madotto, A.,\n",
       "Fung, P.: Survey of Hallucination in Natural Language Gener ation.</span> <span style=\"color: yellow;\">ACM Comput-\n",
       "ing Surveys 55(12), 1–38 (Mar 2023).</span> <span style=\"color: blue;\">https://doi.org/10.1145/3571730, http://\n",
       "dx.doi.org/10.1145/3571730 14 Jimeno Yepes et al.</span> <span style=\"color: magenta;\">16.</span> <span style=\"color: cyan;\">Jiang, A.Q., Sablayrolles, A., Roux, A., Mensch, A., Save ary, B., Bamford, C.,\n",
       "Chaplot, D.S., de las Casas, D., Hanna, E.B., Bressand, F., L engyel, G., Bour, G.,\n",
       "Lample, G., Lavaud, L.R., Saulnier, L., Lachaux, M.A., Stoc k, P., Subramanian,\n",
       "S., Yang, S., Antoniak, S., Scao, T.L., Gervet, T., Lavril, T ., Wang, T., Lacroix,\n",
       "T., Sayed, W.E.</span> <span style=\"color: white;\">: Mixtral of Experts (2024)\n",
       "17.</span> <span style=\"color: red;\">Judge, R., Bentabet, I., Ferradans, S.: The ﬁntoc-2019 sh ared task: Financial doc-\n",
       "ument structure extraction.</span> <span style=\"color: green;\">In: Proceedings of the Second F inancial Narrative\n",
       "Processing Workshop (FNP 2019).</span> <span style=\"color: yellow;\">pp.</span> <span style=\"color: blue;\">51–57 (2019)\n",
       "18.</span> <span style=\"color: magenta;\">Kaddour, J., Harris, J., Mozes, M., Bradley, H., Railean u, R., McHardy, R.: Chal-\n",
       "lenges and applications of large language models.</span> <span style=\"color: cyan;\">arXiv pre print arXiv:2307.10169\n",
       "(2023)\n",
       "19.</span> <span style=\"color: white;\">Kaur, S., Smiley, C., Gupta, A., Sain, J., Wang, D., Sidda gangappa, S.,\n",
       "Aguda, T., Shah, S.: REFinD: Relation Extraction Financial Dataset.</span> <span style=\"color: red;\">In:\n",
       "Proceedings of the 46th International ACM SIGIR Conference on Re-\n",
       "search and Development in Information Retrieval.</span> <span style=\"color: green;\">SIGIR ’23 , ACM (Jul\n",
       "2023).</span> <span style=\"color: yellow;\">https://doi.org/10.1145/3539618.3591911, http://dx.doi.org/10.1145/\n",
       "3539618.3591911\n",
       "20.</span> <span style=\"color: blue;\">Kim, G., Hong, T., Yim, M., Park, J., Yim, J., Hwang, W., Yu n, S., Han, D.,\n",
       "Park, S.: Donut: Document understanding transformer with ut ocr.</span> <span style=\"color: magenta;\">arXiv preprint\n",
       "arXiv:2111.15664 7, 15 (2021)\n",
       "21.</span> <span style=\"color: cyan;\">Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin , V., Goyal, N., K¨ uttler,\n",
       "H., Lewis, M., Yih, W.t., Rockt¨ aschel, T., et al.</span> <span style=\"color: white;\">: Retrieva l-augmented generation\n",
       "for knowledge-intensive NLP tasks.</span> <span style=\"color: red;\">Advances in Neural Info rmation Processing\n",
       "Systems 33, 9459–9474 (2020)\n",
       "22.</span> <span style=\"color: green;\">Li, D., Shao, R., Xie, A., Sheng, Y., Zheng, L., Gonzalez, J.E., Stoica, I., Ma, X.,\n",
       "Zhang, H.: How Long Can Open-Source LLMs Truly Promise on Con text Length?</span> <span style=\"color: yellow;\">(June 2023), https://lmsys.org/blog/2023-06-29-longchat\n",
       "23.</span> <span style=\"color: blue;\">Li, Y., Duan, Y.: The evaluation of experiments of artiﬁc ial general intelligence\n",
       "with gpt-4 based on dikwp.</span> <span style=\"color: magenta;\">arXiv preprint (2023)\n",
       "24.</span> <span style=\"color: cyan;\">Lin, C.Y.</span> <span style=\"color: white;\">: Rogue: A package for automatic evaluation of s ummaries.</span> <span style=\"color: red;\">In: Text sum-\n",
       "marization branches out.</span> <span style=\"color: green;\">pp.</span> <span style=\"color: yellow;\">74–81 (2004)\n",
       "25.</span> <span style=\"color: blue;\">Liu, N.F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqu a, M., Petroni, F., Liang,\n",
       "P.: Lost in the middle: How language models use long contexts .</span> <span style=\"color: magenta;\">arXiv preprint\n",
       "arXiv:2307.03172 (2023)\n",
       "26.</span> <span style=\"color: cyan;\">Liu, Z., Huang, D., Huang, K., Li, Z., Zhao, J.: Finbert: A pre-trained ﬁnancial\n",
       "language representation model for ﬁnancial text mining.</span> <span style=\"color: white;\">In : Proceedings of the\n",
       "twenty-ninthinternationalconferenceoninternational j ointconferencesonartiﬁcial\n",
       "intelligence.</span> <span style=\"color: red;\">pp.</span> <span style=\"color: green;\">4513–4519 (2021)\n",
       "27. llmware: Rag Instruct Benchmark Tester.</span> <span style=\"color: yellow;\">https://huggingface.co/datasets/\n",
       "llmware/rag_instruct_benchmark_tester , Accessed: January 15, 2024\n",
       "28.</span> <span style=\"color: blue;\">Malkov, Y.A., Yashunin, D.A.</span> <span style=\"color: magenta;\">: Eﬃcient and robust approx imate nearest neigh-\n",
       "bor search using hierarchical navigable small world graphs .</span> <span style=\"color: cyan;\">IEEE transactions on\n",
       "pattern analysis and machine intelligence 42(4), 824–836 (2018)\n",
       "29.</span> <span style=\"color: white;\">Moore, S., Nguyen, H.A., Chen, T., Stamper, J.: Assessin g the quality of multiple-\n",
       "choice questions using gpt-4 and rule-based methods.</span> <span style=\"color: red;\">In: Eu ropean Conference on\n",
       "Technology Enhanced Learning.</span> <span style=\"color: green;\">pp.</span> <span style=\"color: yellow;\">229–245.</span> <span style=\"color: blue;\">Springer (2023 )\n",
       "30.</span> <span style=\"color: magenta;\">Naismith, B., Mulcaire, P., Burstein, J.: Automated eva luation of written discourse\n",
       "coherence using gpt-4.</span> <span style=\"color: cyan;\">In: Proceedings of the 18th Workshop on Innovative Use of\n",
       "NLP for Building Educational Applications (BEA 2023).</span> <span style=\"color: white;\">pp.</span> <span style=\"color: red;\">3 94–403 (2023)\n",
       "31.</span> <span style=\"color: green;\">OpenAI, :, Achiam, J., Adler, S., Agarwal, S., et al.</span> <span style=\"color: yellow;\">: GPT -4 Technical Report\n",
       "(2023) Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 15\n",
       "32.</span> <span style=\"color: blue;\">Papineni, K., Roukos, S., Ward, T., Zhu, W.J.</span> <span style=\"color: magenta;\">: Bleu: a met hod for automatic\n",
       "evaluation of machine translation.</span> <span style=\"color: cyan;\">In: Proceedings of the 4 0th annual meeting of\n",
       "the Association for Computational Linguistics.</span> <span style=\"color: white;\">pp.</span> <span style=\"color: red;\">311–31 8 (2002)\n",
       "33.</span> <span style=\"color: green;\">Pﬁtzmann, B., Auer, C., Dolﬁ, M., Nassar, A.S., Staar, P. : Doclaynet: A large\n",
       "human-annotated dataset for document-layout segmentatio n. In: Proceedings of\n",
       "the 28th ACM SIGKDD Conference on Knowledge Discovery and Da ta Mining.</span> <span style=\"color: yellow;\">pp.</span> <span style=\"color: blue;\">3743–3751 (2022)\n",
       "34.</span> <span style=\"color: magenta;\">Pinecone: Chunking strategies for llm applications, https://www.pinecone.io/\n",
       "learn/chunking-strategies/\n",
       "35.</span> <span style=\"color: cyan;\">Reimers, N., Gurevych, I.: Sentence-bert: Sentence emb eddings using siamese bert-\n",
       "networks.</span> <span style=\"color: white;\">In: Proceedings of the 2019 Conference on Empiric al Methods in Nat-\n",
       "ural Language Processing.</span> <span style=\"color: red;\">Association for Computational L inguistics (11 2019),\n",
       "https://arxiv.org/abs/1908.10084\n",
       "36.</span> <span style=\"color: green;\">Retteter, J.: Mastering Table Extraction: Revolutioni ze Your Earnings Re-\n",
       "ports Analysis with AI.</span> <span style=\"color: yellow;\">https://medium.com/unstructured-io/mastering-\n",
       "table-extraction-revolutionize-your-earnings-report s-analysis-with-\n",
       "ai-1bc32c22720e , Accessed: January 15, 2024\n",
       "37.</span> <span style=\"color: blue;\">Rizinski, M., Peshov, H., Mishev, K., Jovanovik,M., Tra janov, D.: SentimentAnal-\n",
       "ysis in Finance: From Transformers Back to eXplainable Lexi cons (XLex) (2023)\n",
       "38.</span> <span style=\"color: magenta;\">Shah, R.S., Chawla, K., Eidnani, D., Shah, A., Du, W., Cha va, S., Raman, N.,\n",
       "Smiley, C., Chen, J., Yang, D.: WHEN FLUE MEETS FLANG: Benchm arks and\n",
       "Large Pre-trained Language Model for Financial Domain (202 2)\n",
       "39.</span> <span style=\"color: cyan;\">Singh Phogat, K., Harsha, C., Dasaratha, S., Ramakrishn a, S., Akhil Puranam, S.:\n",
       "Zero-Shot Question Answering over Financial Documents usi ng Large Language\n",
       "Models.</span> <span style=\"color: white;\">arXiv e-prints pp.</span> <span style=\"color: red;\">arXiv–2311 (2023)\n",
       "40.</span> <span style=\"color: green;\">Wu,S.,Irsoy,O.,Lu,S.,Dabravolski,V.,Dredze,M., Ge hrmann,S.,Kambadur,P.,\n",
       "Rosenberg, D., Mann, G.: BloombergGPT: A Large Language Mod el for Finance\n",
       "(2023)\n",
       "41.</span> <span style=\"color: yellow;\">Xu, P., Ping, W., Wu, X., McAfee, L., Zhu, C., Liu, Z., Subr amanian, S., Bakhtu-\n",
       "rina,E.,Shoeybi,M.,Catanzaro, B.:RetrievalmeetsLongC ontextLargeLanguage\n",
       "Models (2023)\n",
       "42.</span> <span style=\"color: blue;\">Yang, H., Liu, X.Y., Wang, C.D.</span> <span style=\"color: magenta;\">: FinGPT: Open-SourceFin ancial Large Language\n",
       "Models (2023)\n",
       "43.</span> <span style=\"color: cyan;\">Ye, H., Liu, T., Zhang, A., Hua, W., Jia, W.: Cognitive Mir age: A Review of\n",
       "Hallucinations in Large Language Models (2023)\n",
       "44.</span> <span style=\"color: white;\">Zhang, B., Yang, H., Liu, X.Y.</span> <span style=\"color: red;\">: Instruct-FinGPT: Financ ial Sentiment Analysis\n",
       "by Instruction Tuning of General-Purpose Large Language Mo dels (2023)\n",
       "45.</span> <span style=\"color: green;\">Zheng, X., Burdick, D., Popa, L., Zhong, X., Wang, N.X.R.</span> <span style=\"color: yellow;\">: Global table extractor\n",
       "(gte): A framework for joint table identiﬁcation and cell st ructure recognition using\n",
       "visual context.</span> <span style=\"color: blue;\">In: Proceedings of the IEEE/CVF winter conf erence on applications\n",
       "of computer vision.</span> <span style=\"color: magenta;\">pp.</span> <span style=\"color: cyan;\">697–706 (2021)\n",
       "46.</span> <span style=\"color: white;\">Zhu, F., Lei, W., Huang, Y., Wang, C., Zhang, S., Lv, J., Fe ng, F., Chua, T.S.</span> <span style=\"color: red;\">:\n",
       "TAT-QA: A question answering benchmark on a hybrid of tabula r and textual\n",
       "content in ﬁnance.</span> <span style=\"color: green;\">arXiv preprint arXiv:2105.07624 (2021)</span> </td>\n",
       "            <td style=\"text-align: left;\"><span style=\"color: red;\">arXiv:2402.05131v1  [cs.CL]  5 Feb 2024Financial Report Chunking for Eﬀective\n",
       "Retrieval Augmented Generation\n",
       "Antonio Jimeno Yepes, Yao You, Jan Milczek, Sebastian Laverde, an d Leah Li\n",
       "Unstructured Technologies\n",
       "Sacramento, CA, USA\n",
       "leah@unstructured.io\n",
       "https://unstructured.io\n",
       "Abstract. Chunking information is a key step in Retrieval Augmented\n",
       "Generation (RAG). Current research primarily centers on pa ragraph-\n",
       "level chunking. This approach treats all texts as equal and n eglects\n",
       "the information contained in the structure of documents. We propose\n",
       "an expanded approach to chunk documents by moving beyond mer e\n",
       "paragraph-level chunking to chunk primary by structural el ement com-\n",
       "ponents of documents. Dissecting documents into these cons tituent ele-\n",
       "ments creates a new way to chunk documents that yields the bes t chunk\n",
       "size without tuning. We introduce a novel framework that eva luates how\n",
       "chunking based on element types annotated by document under standing\n",
       "models contributes to the overall context and accuracy of th e informa-\n",
       "tion retrieved. We also demonstrate how this approach impac ts RAG\n",
       "assisted Question & Answer task performance.</span> <span style=\"color: green;\">Our research i ncludes a\n",
       "comprehensive analysis of various element types, their rol e in eﬀective\n",
       "information retrieval, and the impact they have on the quali ty of RAG\n",
       "outputs. Findings support that element type based chunking largely im-\n",
       "prove RAG results on ﬁnancial reporting. Through this resea rch, we are\n",
       "also able to answer how to uncover highly accurate RAG.\n",
       "Keywords: Retrieval Augmented Generation ·Document Chunking ·\n",
       "Document Pre-Processing ·Financial Domain ·Large Language Models\n",
       "1 Introduction\n",
       "Existing approaches for document understanding use a combination n of methods\n",
       "from the computer vision and natural language processing domains to identify\n",
       "the diﬀerent components in a document. In the rapidly evolving lands cape of\n",
       "artiﬁcial intelligence, the capability to eﬀectively process unstruct ured data is\n",
       "becoming increasingly critical. Large Language Models (LLMs) like GPT -4 have\n",
       "revolutionized natural language understanding and generation, a s evidenced by\n",
       "their prompt-based functionalities [31], enabling a wide range of applic ations [5].\n",
       "However,the eﬃcacyofthese models is often constrainedby their relianceon the\n",
       "size and quality of the data they process.</span> <span style=\"color: yellow;\">A notable limitation is the re stricted\n",
       "contextualwindowofLLMs,whichhamperstheirabilitytofullycompr ehendthe</span> <span style=\"color: blue;\">2 Jimeno Yepes et al.\n",
       "contents of extensive documents [25,22,18]. By dissecting large vo lumes of text\n",
       "into smaller, more focused segments, LLMs can process each part with greater\n",
       "precision, ensuring a thorough understanding of each section. Th is segmented\n",
       "approach allows for meticulous analysis of unstructured data, ena bling LLMs to\n",
       "construct a more comprehensive and coherent understanding of the entire docu-\n",
       "meant [41]. There remains a challenge in ensuring factual accuracy an d relevance\n",
       "in the generated responses, especially when dealing with complex or e xtensive\n",
       "information.\n",
       "Recently, Retrieval Augmented Generation (RAG) [21,12] has been devel-\n",
       "oped to address the hallucination problem with LLMs [15,43] when recovering\n",
       "factual information directly from an LLM. In RAG, instead of answe ring a user\n",
       "query directly using an LLM, the user query is used to retrieve docu ments or\n",
       "segments from a corpus and the top retrieved documents or segm ents are used\n",
       "to generate the answer in conjunction with an LLM. In this way, RAG con-\n",
       "straints the answer to the set of retrieved documents. RAGs hav e been used as\n",
       "well to answer questions from single documents [14].</span> <span style=\"color: magenta;\">RAGs hav e been used as\n",
       "well to answer questions from single documents [14]. The document s are split\n",
       "into smaller parts or chunks, indexed by a retrieval system and rec overed and\n",
       "processed depending on the user information need. In a sense, th is processallows\n",
       "answering questions about information in a single document, thus co ntributing\n",
       "to the set of techniques available for document understanding.\n",
       "Since documents need to be chunked for RAG processing, this raises the\n",
       "question about what is the best practice to chunk documents for e ﬀective RAG\n",
       "document understanding. There are several dimensions to consid er when decid-\n",
       "ing how to chunk a document, which includes the size of the chunks.\n",
       "The retrieval system in RAG can use traditional retrieval systems using bag-\n",
       "of-words methods or a vector database. If a vector database is used, then an\n",
       "embedding needs to be obtained from each chunk, thus the number of tokens\n",
       "in the chunk is relevant since the neural networks processing the c hunks might\n",
       "have constraints on the number of tokens. As well, diﬀerent chunk sizes might\n",
       "have undesirable retrieval results. Since the most relevant retrie ved chunks need\n",
       "to be processed by an LLM, the number of tokens in retrieved chun ks might\n",
       "have an eﬀect in the generation of the answer [25].</span> <span style=\"color: cyan;\">As we see, chunk ing is re-\n",
       "quired for RAG systems and there are several advantages and dis advantages\n",
       "when considering how to chunk a document.\n",
       "In this work, we study speciﬁcally the chunking of U.S. Securities and Ex-\n",
       "change Commission (SEC)1Financial Reports2, including 10-Ks, 10-Qs, and\n",
       "8-Ks. This study plays a critical role in oﬀering insights into the ﬁnanc ial health\n",
       "and operational dynamics of public companies. These documents pr esent unique\n",
       "challenges in terms of document processing and information extract tion as they\n",
       "consist of varying sizes and layouts, and contain a variety of tabula r informa-\n",
       "tion. Previous work has evaluated the processing of these report s with simple\n",
       "chunking strategies (e.g., tokens), but we believe that a more eﬀec tive use of\n",
       "these reports might be achieved by a better pre-processing of th e documents\n",
       "1https://www.sec.gov\n",
       "2https://www.sec.gov/files/cf-frm.pdf</span> <span style=\"color: white;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 3\n",
       "and chunking conﬁguration3[14]. To the best of our knowledge, this is the ﬁrst\n",
       "systematic study on chunking for document understanding and mo re speciﬁcally\n",
       "for processing ﬁnancial reports.\n",
       "2 Related work\n",
       "RAG is an innovative method that has emerged to enhance the perfo rmance of\n",
       "LLMs by incorporating external knowledge, thereby boosting the ir capabilities.\n",
       "This technique has undergone substantial research, examining va rious conﬁgu-\n",
       "rations and applications. Key research includes Gao et al.’s [12] detaile d analysis\n",
       "of RAG conﬁgurations and their role in enhancing Natural Language Processing\n",
       "(NLP) tasks, reducing errors, and improving factual accuracy. Several context\n",
       "retrieval methods are proposed to dynamically retrieve document s to improve\n",
       "the coherence of generated outputs [1].</span> <span style=\"color: red;\">Other research introdu ced advancements\n",
       "in RAG, including reasoning chain storage and optimization strategies for re-\n",
       "trieval, respectively, broadening the scope and eﬃciency of RAG ap plications in\n",
       "LLMs[21].MorerecentworkhascomparedRAGvsLLMﬁne-tuning,a ndidenti-\n",
       "ﬁed that applying both improves the performance of each individual method [2].\n",
       "Chunkinghasbeen identiﬁed asthe keyfactorinthe successofRAG ,improv-\n",
       "ing the relevance of retrieved content by ensuring accurate embe dding of text\n",
       "with minimal noise. Various strategies have been developed for text subdivision,\n",
       "each with its unique approach. They can be summarized as follows: th eﬁxed\n",
       "size strategy divides text into uniform segments, but it often overlooks the\n",
       "underlying textual structure. In contrast, the recursive strategy iteratively\n",
       "subdivides text using separators like punctuation marks, allowing it t o adapt\n",
       "more ﬂuidly to the content. The contextual strategy takes this a step further\n",
       "by employing NLP techniques such as sentence segmentation to rep resent the\n",
       "meaning in context. Lastly, the hybrid strategy combines diﬀerent approaches,\n",
       "oﬀering greater ﬂexibility in handling diverse text types [34].</span> <span style=\"color: green;\">Howeve r, an area\n",
       "yet to be explored in RAG chunking based on element types (document t struc-\n",
       "ture), which involves analyzing the inherent structure of document ts, such as\n",
       "headings, paragraphs, tables, to guide the chunking process. Alt hough chunk-\n",
       "ing by Markdown and LaTeX comes closer to addressing element type s, it’s not\n",
       "the same in nature as a dedicated approach that directly considers document\n",
       "structure and element types for chunking, which could potentially y ield more\n",
       "contextually relevant chunks.\n",
       "Exploring the structure of ﬁnancial reports is an exceptional are a for es-\n",
       "tablishing optimal principles for chunking. The intricate nature of do cument\n",
       "structures and contents has resulted in most of the work process sing ﬁnancial\n",
       "reports focusing on the identiﬁcation of structural elements. Am ong previous\n",
       "work, we ﬁnd El-Haj et al. [10] and the FinTOC challenges [17,4,11] th at have\n",
       "worked at the document structure level for UK and French ﬁnanc ial reports. Ad-\n",
       "3https://www.cnbc.com/2023/12/19/gpt-and-other-ai-mo dels-cant-analyze-\n",
       "an-sec-filing-researchers-find.html</span> <span style=\"color: yellow;\">4 Jimeno Yepes et al.\n",
       "ditionally, there is recent work that considers U.S. SEC reports, wh ich includes\n",
       "DocLayNet [33] and more speciﬁcally with the report tables in FinTabN et [45].\n",
       "On the side of ﬁnancial models, there is work in sentiment analysis in ﬁ-\n",
       "nance [37], which includes the pre-training of specialised models such a s Fin-\n",
       "BERT by Liu et al. [26], which is a BERT based model pre-trained on large\n",
       "corpora including large collections of ﬁnancial news collected from diﬀ erent sites\n",
       "and FinBERT by DeSola et al, [9] trained on Wikipedia, BookCorpus and U .S.\n",
       "SEC data. Additional models include BloombergGPT [40], FinGPT [42] and\n",
       "Instruct-FinGPT[44].\n",
       "MoreadvancedatasetsintheﬁnancialdomainincludeFinQA[6],LLMWa re[27],\n",
       "ConFIRM [8] and TAT-QA [46] among others [7,38,19] that have been p repared\n",
       "for retrieval and or Questions and Answering (Q&A) tasks over sn ippets of ﬁ-\n",
       "nancial data that includes tabular data, which has allowed methods o n large\n",
       "language models to be tested on them [39].</span> <span style=\"color: blue;\">Most of the previous work has focused on understanding the layout t of ﬁ-\n",
       "nancial documents or understanding speciﬁc snippets of existing r eports with\n",
       "diﬀerent levels of complexity, but there has not been much researc h in under-\n",
       "standingﬁnancialreportdocuments,exceptsomemorerecentw orkthatincludes\n",
       "FinanceBench [14], in which a set of questions about the content of ﬁ nancial re-\n",
       "ports are proposed that includes the evidence snippet.\n",
       "More speciﬁcally on document chunking methods for RAG, there are stan-\n",
       "dard approaches being considered such as chunking text into span s of a given\n",
       "token length (e.g. 128 and 256) or chunking based on sentences. O pen source\n",
       "projects already allow simple processing of documents (e.g. Unstru ctured4, Lla-\n",
       "maindex5or Langchain6), without explicitly considering the table structure on\n",
       "which these chunking strategies are applied.\n",
       "Even though diﬀerent approaches are available, an exhaustive eva luation of\n",
       "chunking applied to RAG and speciﬁcally to ﬁnancial reporting, excep t for some\n",
       "limited chunking analysis [14,36], is non-existent.</span> <span style=\"color: magenta;\">In our work, we comp are a\n",
       "broad range of chunking approachesin addition to more simple ones a nd provide\n",
       "an analysis of the outcomes of diﬀerent methods when asking quest ions about\n",
       "diﬀerent aspects of the reports.\n",
       "3 Methods\n",
       "In this section, wepresentthe chunkingstrategiesthat we havee valuated. Before\n",
       "describing the chunking strategies, we present the RAG environme nt in which\n",
       "these strategies have been evaluated and the dataset used for e valuation.\n",
       "3.1 RAG setting for the experiments\n",
       "The RAG pipeline used to process a user question is presented in ﬁgur e 1 and is\n",
       "a common instance ofa RAG [12]. Priorto answeringany question abo ut a given\n",
       "4https://unstructured.io\n",
       "5https://www.llamaindex.ai\n",
       "6https://www.langchain.com</span> <span style=\"color: cyan;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 5\n",
       "document, the document is split into chunks and the chunks are inde xed into\n",
       "a vector database (vectordb). When a question is sent to the RAG system, the\n",
       "top-k chunks most similar to the question are retrieved from the ve ctor database\n",
       "and used to generate the answer using a large language model as ge nerator. In\n",
       "order to retrieve chunks from the vector database, the questio n is encoded into a\n",
       "vector that is compared to the vector previously generated from the chunks. To\n",
       "prompt the generator, the question is converted into a set of inst ructions that\n",
       "instruct the LLM to ﬁnd the answer within the top-k retrieved chun ks.\n",
       "Fig.1.RAG steps to answer a question about a document\n",
       "In our experiments, we modify the way documents are chunked prior to\n",
       "being indexed in the vector database. All other settings remain con stant. In the\n",
       "following sections, we describe in more detail each one of the compon ents and\n",
       "processes used.\n",
       "3.2 Indexing and retrieval\n",
       "We have used the open source system Weaviate7as our vector database.</span> <span style=\"color: white;\">As\n",
       "encoder model, we have used a sentence transformer [35] trained on over 256M\n",
       "questions and answers, which is available from the HuggingFace syst em8.\n",
       "As shown in ﬁgure 2, to index a document, ﬁrst the document is split in to\n",
       "chunks, then each chunk is processed by an encoder model and th en indexed into\n",
       "the vector database. Based on the chunking strategy a document t will be split\n",
       "into a larger or smaller set of chunks.\n",
       "Fig.2.Indexing of document chunks into the vector database\n",
       "7https://weaviate.io/developers/weaviate\n",
       "8https://huggingface.co/sentence-transformers/multi- qa-mpnet-base-dot-\n",
       "v1</span> <span style=\"color: red;\">6 Jimeno Yepes et al.\n",
       "As shown in ﬁgure 1, to retrievechunks relevant to a question, the question is\n",
       "converted into a vector representation and the vector database e returns a ranked\n",
       "list of chunks based on the similarity between question vector and th e chunks\n",
       "in the database. Weaviate implements an approximate nearest neigh bours algo-\n",
       "rhythm [28] as their retrieval approach, which supports fast retrie val with high\n",
       "accuracy. In our experiments, we retrieve the top-10 chunks fo r each question.\n",
       "3.3 Generation\n",
       "Once the vector database has retrieved the top-10 chunks base d on a question,\n",
       "the generation module generates the answer. To do so, a prompt b ased on the\n",
       "question and the retrieved chunks are provided to a large language model that\n",
       "generates the answer of the system.\n",
       "WehaveusedGPT-4[31]asthegenerator,whichhasshownbestpe rformance\n",
       "compared to earlier versions. As well, its performance was better c ompared to\n",
       "existing open source alternatives [22] such as Mixtral [16]. We used t he prompt\n",
       "presented in ﬁgure 3 that we designed on another similar RAG implement tation\n",
       "with diﬀerent document types.</span> <span style=\"color: green;\">The prompt conditions the answer t o the query\n",
       "and the chunks, referred to as source, and if the generator cannot answer it\n",
       "should return No answer .\n",
       "please answer the question below by referencing the list of s ources\n",
       "provided after the question; if the question can not be answe red just\n",
       "respond ’No answer’. The sources are listed after \"Sources: \".\n",
       "Question: {query}\n",
       "Sources: {key} - {source}\n",
       "...\n",
       "Fig.3.Example prompt template used by the generator\n",
       "3.4 Chunking\n",
       "As a baseline chunking method, we have split the documents into chun ks of size\n",
       "ntokens (n∈ {128,256,512}). As well, an aggregation of the output by the\n",
       "indexing of diﬀerent chunking conﬁgurations has been considered.\n",
       "In addition to chunking based on the number of tokens, we have pro cessed\n",
       "the documents using computer vision and natural language process singto extract\n",
       "elements identiﬁed in the reports. The list of elements considered ar e provided\n",
       "by the Unstructured9open source library. From the set of processing strategies,\n",
       "9https://unstructured-io.github.io/unstructured/intr oduction.html#\n",
       "elements</span> <span style=\"color: yellow;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 7\n",
       "we use Chipper, a vision encoder decoder10model inspired by Donut [20] to\n",
       "showcase the performance diﬀerence. The Chipper model output s results as a\n",
       "JSON representation of the document, listing elements per page ch aracterized\n",
       "by their element type. Additionally, Chipper provides a bounding box e nclosing\n",
       "each element on the page and the corresponding element text.\n",
       "These elements are sometimes short to be considered as chunks, s o to gen-\n",
       "erate chunks from elements the following steps have been followed. Given the\n",
       "structureofﬁnancereportingdocuments,ourstructuralchu nkingeﬀortsarecon-\n",
       "centrated on processing titles, texts, and tables.</span> <span style=\"color: blue;\">The steps to g enerate element-\n",
       "based chunks are:\n",
       "–if the element text length is smaller than 2,048 characters, a merge w ith the\n",
       "following element is attempted\n",
       "–iteratively, element texts are merged following the step above till eit her the\n",
       "desired length is achieved, without breaking the element\n",
       "–if a title element is found, a new chunk is started\n",
       "–if a table element is found, a new chunk is started, preservingthe en tire table\n",
       "After element-based chunks have been derived, three types of m etadata are\n",
       "generated to enrich the content and support eﬃcient indexing. Th e ﬁrst two\n",
       "types, generated via predeﬁned prompt templates with GPT-4, inc lude: 1) up to\n",
       "6 representative keywords of the composite chunk 2) a summarise d paragraph\n",
       "of the composite chunk. The third type is 3) Naive representation u sing the ﬁrst\n",
       "two sentences from a composite chunk (a kind of preﬁx) and in the c ase oftables,\n",
       "the description of the table, which is typically identiﬁed in the table cap tion.\n",
       "3.5 Dataset\n",
       "To evaluate the performance of the diﬀerent chunking approache s, we have used\n",
       "the FinanceBenchdataset [14].</span> <span style=\"color: magenta;\">FinanceBench is anew benchmarking datasetde-\n",
       "signed to assess the capabilities of LLMs in answering open-book ﬁna ncial ques-\n",
       "tions. The questions collected are realistic and applicable to real-wor ld ﬁnancial\n",
       "scenarios and include complex questions that require computationa l reasoning\n",
       "to arrive at conclusive answers.\n",
       "This dataset is made of 150 instances with questions and answers fr om 84\n",
       "unique reports. The dataset does not include the source document ts, which we\n",
       "have downloaded. We were able to recover only 80 documents, which reduces\n",
       "the number of questions to 141 from the original 150. The distribut ion of Un-\n",
       "structured elements predictions are shown in table 1.\n",
       "Documents have a varying number of pages, spanning from 4 pages (FOOT-\n",
       "LOCKER 20228Kdated-2022-05-20) to 549 pages (e.g. PEPSICO 202110K),\n",
       "with an average of 147.34 with std 97.78 with a total of 11,787 pages c ombined.\n",
       "Each instance contains a link to the report, the question, a questio n type , the\n",
       "answerand supportingevidence,with pagenumberwherethe evide nce islocated\n",
       "10https://huggingface.co/docs/transformers/model_doc/ vision-encoder-\n",
       "decoder</span> <span style=\"color: cyan;\">8 Jimeno Yepes et al.\n",
       "Table 1. Unstructured element types distribution for Chipper predictions against doc-\n",
       "uments in FinanceBench.\n",
       "Element Type Chipper Entities\n",
       "NarrativeText 61,780\n",
       "Title 29,664\n",
       "ListItem 33,054\n",
       "UncategorizedText 9,400\n",
       "Footer 1,026\n",
       "Table 7,700\n",
       "Header 3,959\n",
       "Image 26\n",
       "FigureCaption 54\n",
       "Formula 29\n",
       "Address 229\n",
       "Total 146,921\n",
       "in the document, that allows for a closer evaluation of the results. B ased on the\n",
       "page number, evidence contexts are located in diﬀerent areas in th e documents,\n",
       "ranging from the ﬁrst page in some cases up to page 304 in one instan ce. The\n",
       "mean page number to ﬁnd the evidence is 54.58 with a standard deviat ion of\n",
       "43.66, which shows that evidence contexts to answer the question s are spread\n",
       "within a document. These characteristics make FinanceBench a per fect dataset\n",
       "for evaluating RAG. An example instance is available in table 2.\n",
       "4 Results\n",
       "Inthissection,weevaluatethediﬀerentchunkingstrategiesusing theFinanceBench\n",
       "dataset.</span> <span style=\"color: white;\">Our evaluation is grounded in factual accuracy, which allow ws us to mea-\n",
       "sure the eﬀectiveness of each conﬁguration by its precision in retr ieving answers\n",
       "that match the ground truth, as well as its generation abilities.\n",
       "We are considering 80 documents and 141 questions from FinanceBe nch.\n",
       "Using the OpenAI tokenizer from the model text-embedding-ada-002 that uses\n",
       "the tokenizer cl100kbase11, there are on average 102,444.35 tokens with std of\n",
       "61,979.45, which shows the large variability of document lengths as se en by the\n",
       "diﬀerent number of pages per document presented above.\n",
       "Chunking Eﬃciency The ﬁrst thing we analyzed is the total number of\n",
       "chunks, as it impacts indexing time. We would like to observe the relatio nship\n",
       "between accuracy and total chunk size. Table 3 shows the number of chunks\n",
       "derived from each one of the processing methods. Unstructured element-based\n",
       "chunks are closer in size to Base 512, and as the chunk size decrease es for the\n",
       "basic chunking strategies, the total number of chunks increases linearly.\n",
       "11https://platform.openai.com/docs/guides/embeddings/ limitations-risks</span> <span style=\"color: red;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 9\n",
       "Table 2. Example question from the FinanceBench dataset\n",
       "Field Value\n",
       "ﬁnancebench idﬁnancebench id00859\n",
       "docname VERIZON 202110K\n",
       "doclink https://www.verizon.com/about/sites/default/ﬁles/20 21-Annual-\n",
       "Report-on-Form-10-K.pdf\n",
       "question type’novel-generated’\n",
       "question Among all of the derivative instruments that Verizon used to manage\n",
       "the exposure to ﬂuctuations of foreign currencies exchange rates or\n",
       "interest rates, which one had the highest notional value in F Y 2021?\n",
       "answer Cross currency swaps. Its notional value was $32,502 million.,\n",
       "evidence textDerivative Instruments We enter into derivative transacti owns primarily\n",
       "to manage our exposure to ﬂuctuations in foreign currency ex change\n",
       "rates and interest rates. We employ risk management strateg ies, which\n",
       "may include the use of a variety of derivatives including int erest rate\n",
       "swaps, cross currency swaps, forward starting interest rat e swaps, trea-\n",
       "sury rate locks, interest rate caps, swaptions and foreign e xchange for-\n",
       "wards. We do not hold derivatives for trading purposes.</span> <span style=\"color: green;\">We do not hold derivatives for trading purposes. The f ollowing\n",
       "table sets forth the notional amounts of our outstanding der ivative in-\n",
       "struments: (dollars in millions) AtDecember 31, 2021 2020 I nterestrate\n",
       "swaps $19,779 $17,768 Cross currency swaps 32,502 26,288 Forward\n",
       "starting interest rate swaps 1,000 2,000 Foreign exchange f orwards 932\n",
       "1,405\n",
       "pagenumber 85\n",
       "Table 3. Chunks statistics for basic chunking elements and Unstruct ured elements\n",
       "Processing total chunks mean chunks per document (std) tables mean (std)\n",
       "Base 128 64,058 800.73 (484.11) N/A\n",
       "Base 256 32,051 400.64 (242.04) N/A\n",
       "Base 512 16,046 200.58 (121.01) N/A\n",
       "Chipper 20,843 260.57 (145.80) 96.20 (57.53)\n",
       "Retrieval Accuracy Secondly, we evaluate the capabilities of each chunking\n",
       "strategy in terms of retrieval accuracy.</span> <span style=\"color: yellow;\">We use the page number s in the ground\n",
       "truth to calculate the page-level retrieval accuracy, and we use ROGUE [24] and\n",
       "BLEU [32] scores to evaluate the accuracy of paragraph-levelre trieval compared\n",
       "to the ground truth evidence paragraphs.\n",
       "As shown in Table 4, when compared to Unstructured element-base d chunk-\n",
       "ing strategies, basic chunking strategies seem to have higher page -level retrieval\n",
       "accuracy but lower paragraph-level accuracy on average. Addit ionally, basic\n",
       "chunking strategies also lack consistency between page-level and paragraph-level\n",
       "accuracy; higher page-level accuracy doesn’t ensure higher par agraph-level ac-\n",
       "curacy. For example, Base 128 has the second highest page-level accuracy but</span> <span style=\"color: blue;\">10 Jimeno Yepes et al.\n",
       "the lowest paragraph-level scores among all. On the other hand, e lement-based\n",
       "chunking strategies showed more consistent results.\n",
       "A fascinating discovery is that when various chunking strategies ar e com-\n",
       "bined, it results in enhanced retrieval scores, achieving superior p performance\n",
       "at both the page level (84.4%) and paragraph level (with ROGUE at 0 .568%\n",
       "and BLEU at 0.452%). This ﬁnding addresses an unresolved question : how to\n",
       "improve the accuracy of RAG.\n",
       "The element based method provides the highest scores and it also pr ovides a\n",
       "mechanism to chunk documents without the need to ﬁne tune hyper -parameters\n",
       "like the number of tokens in a chunk. This suggests the element base d method\n",
       "is more generalizable and can be applied to new types of documents.\n",
       "Q&A Accuracy Third, we evaluate the Q&Aaccuracyfor the chunking strate-\n",
       "gies.Inadditiontomanualevaluation,wehaveinvestigatedanauto maticevalua-\n",
       "tionusingGPT-4.GPT-4compareshowtheanswersprovidedbyour methodare\n",
       "similar to or diﬀerent from the FinanceBench gold standard, similar ap proaches\n",
       "have been previously evaluated [13,23,29,30].</span> <span style=\"color: magenta;\">The automatic evaluatio n allows\n",
       "scaling the evaluation eﬀorts for the diﬀerent chunking strategies that we have\n",
       "considered. We used the prompt template in ﬁgure 4.\n",
       "Begin with True or False. Are the two following answers (Answ er 1 and\n",
       "Answer 2) the same with respect to the question between single e quotes\n",
       "’{question}’?\n",
       "Answer 1: ’{ground_truth_answer}’\n",
       "Answer 2: ’{generated_answer}’\n",
       "Fig.4.Evaluation prompt template. The {question },{groundtruthanswer}and\n",
       "{generated answer}ﬁelds are substituted for each question accordingly.\n",
       "Results in table 5 show that element-based chunking strategies oﬀe r the best\n",
       "question-answering accuracy, which is consistent with page retrie val and para-\n",
       "graph retrieval accuracy.\n",
       "Lastly, our approach stands out for its eﬃciency. Not only is element t-based\n",
       "chunking generalizable without the need to select the chunk size, bu t when com-\n",
       "pared to the aggregation results that yield the highest retrieval s cores. Element-\n",
       "based chunking achieves the highest retrieval scores with only half the number\n",
       "of chunks required compared to methods that do not consider the structure of\n",
       "the documents (62,529 v.s. 112,155).</span> <span style=\"color: cyan;\">112,155). This can reduce the indexing c ost and im-\n",
       "prove query latency because there are only half as many vectors t o index for the\n",
       "vectordb that stores the chunks. This underscores the eﬀectiv eness of our solu-\n",
       "tion in optimizing the balance between performance and computation al resource\n",
       "requirements.</span> <span style=\"color: white;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 11\n",
       "Table 4. Retrieval results. For each chunking strategy, we show the n umber of chunks\n",
       "for all the documents (Total Chunks), Page Accuracy, and ROU GE and BLEU scores.\n",
       "ROGUE and BLEU are calculated as the maximum score from the li st of recovered\n",
       "contexts for a question when compared to the known evidence f or that question.\n",
       "Chunking strategy Total Chunks Page Accuracy ROGUE BLEU\n",
       "Base 128 64,058 72.34 0.3830.181\n",
       "Base 256 32,051 73.05 0.4330.231\n",
       "Base 512 16,046 68.09 0.4550.250\n",
       "Base Aggregation 112,155 83.69 0.5360.277\n",
       "Keywords Chipper 20,843 46.10 0.4440.315\n",
       "Summary Chipper 20,843 62.41 0.4730.350\n",
       "Preﬁx & Table Description Chipper 20,843 67.38 0.5140.400\n",
       "Chipper Aggregation 62,529 84.40 0.5680.452\n",
       "Table 5. Q&A results.</span> <span style=\"color: red;\">Q&A results. We show the percentage of questions with no answ er and as\n",
       "well the accuracy either estimated automatically using GPT -4 or manually.\n",
       "Chunking strategy No answer GPT-4Manual\n",
       "Base 128 35.46 29.0835.46\n",
       "Base 256 25.53 32.6236.88\n",
       "Base 512 24.82 41.8448.23\n",
       "Keywords Chipper 22.70 43.9753.19\n",
       "Summary Chipper 17.73 43.9751.77\n",
       "Preﬁx & Table Description Chipper 20.57 41.1353.19\n",
       "5 Discussion\n",
       "Results demonstrate the eﬃcacy of our approach in utilizing struct ural elements\n",
       "for chunking, which has enabled us to attain state-of-the-art pe rformance on\n",
       "Q&A tasks within the FinanceBench dataset (accuracy of 50% vs 53 .19%) when\n",
       "an index is createdfromdocument chunksand used forgeneration .Thismethod,\n",
       "which we refer to as element base chunking , has shown to yield consistent results\n",
       "between retrieval and Q&A accuracy.</span> <span style=\"color: green;\">We have observed that using basic 512 chunking strategies produc es results\n",
       "most similar to the Unstructured element-based approach, which m ay be due\n",
       "to the fact that 512 tokens share a similar length with the token size within\n",
       "our element-based chunks and capture a long context, but fail ke ep a coherent\n",
       "context in some cases, leaving out relevant information required fo r Q&A. This\n",
       "is further observed when considering the ROGUE and BLEU scores in table 4,\n",
       "where the chunk contexts for the baseline have lower scores.\n",
       "These ﬁndings support existing research stating that the best ba sic chunk\n",
       "size varies from data to data [3]. These results show, as well, that ou r method\n",
       "adapts to diﬀerent documents without tuning. Our method relies on the struc-</span> <span style=\"color: yellow;\">12 Jimeno Yepes et al.\n",
       "tural information that is present in the document’s layout to adjus t the chunk\n",
       "size automatically.\n",
       "We have evaluated aggregating the output of diﬀerent chunking me thods in\n",
       "the retrieval experiments as sown in table 4. Even though the aggr egationseems\n",
       "to be eﬀective for retrieval, the Q&A exceeded the GPT-4 token limit , which\n",
       "resulted in a non-eﬀective Q&A solution using the selected model.\n",
       "As well, we evaluated variations of the prompt used to generate the answers\n",
       "(see ﬁgure 3). Re-ordering the retrieval context and the quest ion, but results\n",
       "were not statistically diﬀerent. We experimented as well with variatio ns of the\n",
       "verbs using in the prompt, e.g. changing referencing withusing, which seemed to\n",
       "lower the quality of the answers generated. This shows that promp t engineering\n",
       "is a relevant factor in RAG.</span> <span style=\"color: blue;\">This shows that promp t engineering\n",
       "is a relevant factor in RAG.\n",
       "We evaluated using GPT-4 for evaluation instead of relying on manual evalu-\n",
       "ation.Inmostcases,GPT-4evaluatedcorrectlybut failedwhenam oreelaborate\n",
       "answerisprovided.As shown in ﬁgure5, the answeris 39.7%while the e stimated\n",
       "answer is 39.73% but with a detailed explanation of the calculation.\n",
       "Question: ’What is Coca Cola’s FY2021 COGS % margin? Calcula te what\n",
       "was asked by utilizing the line items clearly shown in the inc ome\n",
       "statement.’?\n",
       "Answer 1: ’39.7%’\n",
       "Answer 2: ’From the income statement referenced on page 60 of\n",
       "COCACOLA_2021_10K_embedded.json, we can see that Coca Col a’s total\n",
       "revenue in FY2021 was $38,655 million and their cost of goods sold\n",
       "(COGS) was $15,357 million.</span> <span style=\"color: magenta;\">To calculate the COGS % margin, w e divide\n",
       "the COGS by the total revenue and multiply by 100:\n",
       "(15,357 / 38,655) * 100 = 39.73%\n",
       "So, Coca Cola’s FY2021 COGS % margin was approximately 39.73 %.’\n",
       "Fig.5.Evaluation prompt template\n",
       "6 Conclusions and Future Work\n",
       "Resultsshowthatourelementbasedchunkingstrategyimprovest hestate-of-the-\n",
       "art Q&A for the task, which is achieved by providing a better chunkin g strategy\n",
       "for the processed documents. We provide comparison with baseline chunking\n",
       "strategies that allow us to draw conclusions about diﬀerent chunkin g methods.\n",
       "As future work, we would like to perform a similar evaluation in other do -\n",
       "mains, e.g. biomedical, to understand how our ﬁndings apply outside ﬁ nancial\n",
       "reporting.As well,wewouldlikestudying whichadditionalelementtype s and/or\n",
       "relation between elements would support better chunking strateg ies for RAG.</span> <span style=\"color: cyan;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 13\n",
       "Furthermore, we would like to study the impact of RAG conﬁguration and ele-\n",
       "meant type based chunking.\n",
       "References\n",
       "1. Anantha, R., Bethi, T., Vodianik, D., Chappidi, S.: Conte xt Tuning for Retrieval\n",
       "Augmented Generation (2023)\n",
       "2. Balaguer, A., Benara, V., de Freitas Cunha, R.L., de M. Est ev˜ ao Filho, R., Hendry,\n",
       "T., Holstein, D., Marsman, J., Mecklenburg, N., Malvar, S., Nunes, L.O., Padilha,\n",
       "R., Sharp, M., Silva, B., Sharma, S., Aski, V., Chandra, R.: R ag vs ﬁne-tuning:\n",
       "Pipelines, tradeoﬀs, and a case study on agriculture (2024)\n",
       "3. Barnett, S., Kurniawan, S., Thudumu, S., Brannelly, Z., A bdelrazek, M.: Seven\n",
       "Failure Points When Engineering a Retrieval Augmented Gene ration System\n",
       "(2024)\n",
       "4.</span> <span style=\"color: white;\">Bentabet,N.I.,Judge, R.,ElMaarouf, I.,Mouilleron, V., Valsamou-Stanislawski, D.,\n",
       "El-Haj, M.: The ﬁnancial document structure extraction sha red task (ﬁntoc 2020).\n",
       "In: Proceedings of the 1st Joint Workshop on Financial Narra tive Processing and\n",
       "MultiLing Financial Summarisation. pp. 13–22 (2020)\n",
       "5. Chen, H., Jiao, F., Li, X., Qin, C., Ravaut, M., Zhao, R., Xi ong, C., Joty, S.: Chat-\n",
       "GPT’s One-year Anniversary: Are Open-Source Large Language e Models Catching\n",
       "up? arXiv preprint arXiv:2311.16989 (2023)\n",
       "6. Chen, Z., Chen, W., Smiley, C., Shah, S., Borova, I., Langd on, D., Moussa, R.,\n",
       "Beane, M., Huang, T.H., Routledge, B., et al.: Finqa: A data et of numerical\n",
       "reasoning over ﬁnancial data. arXiv preprint arXiv:2109.0 0122 (2021)\n",
       "7.</span> <span style=\"color: red;\">Chen, Z., Li, S., Smiley, C., Ma, Z., Shah, S., Wang, W.Y.: C onvFinQA: Exploring\n",
       "the Chain of Numerical Reasoning in Conversational Finance Question Answering\n",
       "(2022)\n",
       "8. Choi, S., Gazeley, W., Wong, S.H., Li, T.: Conversational Financial Information\n",
       "Retrieval Model (ConFIRM). arXiv preprint arXiv:2310.130 01 (2023)\n",
       "9. DeSola, V., Hanna, K., Nonis, P.: Finbert: pre-trained mo del on sec ﬁlings for\n",
       "ﬁnancial natural language tasks. University of California (2019)\n",
       "10. El-Haj, M., Rayson, P., Young, S., Walker, M.: Detecting document structure in a\n",
       "very large corpus of UK ﬁnancial reports. European Language Resources Associa-\n",
       "tion (ELRA) (2014)\n",
       "11. El Maarouf, I., Kang, J., Azzi, A.A., Bellato, S., Gan, M. , El-Haj, M.: The ﬁnancial\n",
       "document structure extraction shared task (FinTOC2021). I n: Proceedings of the\n",
       "3rd Financial Narrative Processing Workshop. pp.</span> <span style=\"color: green;\">I n: Proceedings of the\n",
       "3rd Financial Narrative Processing Workshop. pp. 111–119 ( 2021)\n",
       "12. Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y ., Sun, J., Wang,\n",
       "H.: Retrieval-augmented generation for large language mod els: A survey. arXiv\n",
       "preprint arXiv:2312.10997 (2023)\n",
       "13. Hada, R., Gumma, V., de Wynter, A., Diddee, H., Ahmed, M., Choudhury, M.,\n",
       "Bali, K., Sitaram, S.: Are large language model-based evalu ators the solution to\n",
       "scaling up multilingual evaluation? arXiv preprint arXiv: 2309.07462 (2023)\n",
       "14. Islam, P., Kannappan, A., Kiela, D., Qian, R., Scherrer, N., Vidgen, B.: Fi-\n",
       "nanceBench: A New Benchmark for Financial Question Answeri ng. arXiv preprint\n",
       "arXiv:2311.11944 (2023)\n",
       "15.</span> <span style=\"color: yellow;\">Ji, Z., Lee, N., Frieske,R., Yu,T., Su,D.,Xu,Y., Ishii, E., Bang, Y.J., Madotto, A.,\n",
       "Fung, P.: Survey of Hallucination in Natural Language Gener ation. ACM Comput-\n",
       "ing Surveys 55(12), 1–38 (Mar 2023). https://doi.org/10.1145/3571730, http://\n",
       "dx.doi.org/10.1145/3571730</span> <span style=\"color: blue;\">14 Jimeno Yepes et al.\n",
       "16. Jiang, A.Q., Sablayrolles, A., Roux, A., Mensch, A., Save ary, B., Bamford, C.,\n",
       "Chaplot, D.S., de las Casas, D., Hanna, E.B., Bressand, F., L engyel, G., Bour, G.,\n",
       "Lample, G., Lavaud, L.R., Saulnier, L., Lachaux, M.A., Stoc k, P., Subramanian,\n",
       "S., Yang, S., Antoniak, S., Scao, T.L., Gervet, T., Lavril, T ., Wang, T., Lacroix,\n",
       "T., Sayed, W.E.: Mixtral of Experts (2024)\n",
       "17. Judge, R., Bentabet, I., Ferradans, S.: The ﬁntoc-2019 sh ared task: Financial doc-\n",
       "ument structure extraction. In: Proceedings of the Second F inancial Narrative\n",
       "Processing Workshop (FNP 2019). pp. 51–57 (2019)\n",
       "18. Kaddour, J., Harris, J., Mozes, M., Bradley, H., Railean u, R., McHardy, R.: Chal-\n",
       "lenges and applications of large language models.</span> <span style=\"color: magenta;\">arXiv pre print arXiv:2307.10169\n",
       "(2023)\n",
       "19. Kaur, S., Smiley, C., Gupta, A., Sain, J., Wang, D., Sidda gangappa, S.,\n",
       "Aguda, T., Shah, S.: REFinD: Relation Extraction Financial Dataset. In:\n",
       "Proceedings of the 46th International ACM SIGIR Conference on Re-\n",
       "search and Development in Information Retrieval. SIGIR ’23 , ACM (Jul\n",
       "2023). https://doi.org/10.1145/3539618.3591911, http://dx.doi.org/10.1145/\n",
       "3539618.3591911\n",
       "20. Kim, G., Hong, T., Yim, M., Park, J., Yim, J., Hwang, W., Yu n, S., Han, D.,\n",
       "Park, S.: Donut: Document understanding transformer with ut ocr. arXiv preprint\n",
       "arXiv:2111.15664 7, 15 (2021)\n",
       "21.</span> <span style=\"color: cyan;\">Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin , V., Goyal, N., K¨ uttler,\n",
       "H., Lewis, M., Yih, W.t., Rockt¨ aschel, T., et al.: Retrieva l-augmented generation\n",
       "for knowledge-intensive NLP tasks. Advances in Neural Info rmation Processing\n",
       "Systems 33, 9459–9474 (2020)\n",
       "22. Li, D., Shao, R., Xie, A., Sheng, Y., Zheng, L., Gonzalez, J.E., Stoica, I., Ma, X.,\n",
       "Zhang, H.: How Long Can Open-Source LLMs Truly Promise on Con text Length?\n",
       "(June 2023), https://lmsys.org/blog/2023-06-29-longchat\n",
       "23. Li, Y., Duan, Y.: The evaluation of experiments of artiﬁc ial general intelligence\n",
       "with gpt-4 based on dikwp. arXiv preprint (2023)\n",
       "24. Lin, C.Y.: Rogue: A package for automatic evaluation of s ummaries. In: Text sum-\n",
       "marization branches out. pp. 74–81 (2004)\n",
       "25.</span> <span style=\"color: white;\">pp. 74–81 (2004)\n",
       "25. Liu, N.F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqu a, M., Petroni, F., Liang,\n",
       "P.: Lost in the middle: How language models use long contexts . arXiv preprint\n",
       "arXiv:2307.03172 (2023)\n",
       "26. Liu, Z., Huang, D., Huang, K., Li, Z., Zhao, J.: Finbert: A pre-trained ﬁnancial\n",
       "language representation model for ﬁnancial text mining. In : Proceedings of the\n",
       "twenty-ninthinternationalconferenceoninternational j ointconferencesonartiﬁcial\n",
       "intelligence. pp. 4513–4519 (2021)\n",
       "27. llmware: Rag Instruct Benchmark Tester. https://huggingface.co/datasets/\n",
       "llmware/rag_instruct_benchmark_tester , Accessed: January 15, 2024\n",
       "28. Malkov, Y.A., Yashunin, D.A.: Eﬃcient and robust approx imate nearest neigh-\n",
       "bor search using hierarchical navigable small world graphs . IEEE transactions on\n",
       "pattern analysis and machine intelligence 42(4), 824–836 (2018)\n",
       "29.</span> <span style=\"color: red;\">Moore, S., Nguyen, H.A., Chen, T., Stamper, J.: Assessin g the quality of multiple-\n",
       "choice questions using gpt-4 and rule-based methods. In: Eu ropean Conference on\n",
       "Technology Enhanced Learning. pp. 229–245. Springer (2023 )\n",
       "30. Naismith, B., Mulcaire, P., Burstein, J.: Automated eva luation of written discourse\n",
       "coherence using gpt-4. In: Proceedings of the 18th Workshop on Innovative Use of\n",
       "NLP for Building Educational Applications (BEA 2023). pp. 3 94–403 (2023)\n",
       "31. OpenAI, :, Achiam, J., Adler, S., Agarwal, S., et al.: GPT -4 Technical Report\n",
       "(2023)</span> <span style=\"color: green;\">Financial Report Chunking for Eﬀective Retrieval Augmente d Generation 15\n",
       "32. Papineni, K., Roukos, S., Ward, T., Zhu, W.J.: Bleu: a met hod for automatic\n",
       "evaluation of machine translation. In: Proceedings of the 4 0th annual meeting of\n",
       "the Association for Computational Linguistics. pp. 311–31 8 (2002)\n",
       "33. Pﬁtzmann, B., Auer, C., Dolﬁ, M., Nassar, A.S., Staar, P. : Doclaynet: A large\n",
       "human-annotated dataset for document-layout segmentatio n. In: Proceedings of\n",
       "the 28th ACM SIGKDD Conference on Knowledge Discovery and Da ta Mining.\n",
       "pp. 3743–3751 (2022)\n",
       "34. Pinecone: Chunking strategies for llm applications, https://www.pinecone.io/\n",
       "learn/chunking-strategies/\n",
       "35. Reimers, N., Gurevych, I.: Sentence-bert: Sentence emb eddings using siamese bert-\n",
       "networks. In: Proceedings of the 2019 Conference on Empiric al Methods in Nat-\n",
       "ural Language Processing.</span> <span style=\"color: yellow;\">Association for Computational L inguistics (11 2019),\n",
       "https://arxiv.org/abs/1908.10084\n",
       "36. Retteter, J.: Mastering Table Extraction: Revolutioni ze Your Earnings Re-\n",
       "ports Analysis with AI. https://medium.com/unstructured-io/mastering-\n",
       "table-extraction-revolutionize-your-earnings-report s-analysis-with-\n",
       "ai-1bc32c22720e , Accessed: January 15, 2024\n",
       "37. Rizinski, M., Peshov, H., Mishev, K., Jovanovik,M., Tra janov, D.: SentimentAnal-\n",
       "ysis in Finance: From Transformers Back to eXplainable Lexi cons (XLex) (2023)\n",
       "38. Shah, R.S., Chawla, K., Eidnani, D., Shah, A., Du, W., Cha va, S., Raman, N.,\n",
       "Smiley, C., Chen, J., Yang, D.: WHEN FLUE MEETS FLANG: Benchm arks and\n",
       "Large Pre-trained Language Model for Financial Domain (202 2)\n",
       "39.</span> <span style=\"color: blue;\">Singh Phogat, K., Harsha, C., Dasaratha, S., Ramakrishn a, S., Akhil Puranam, S.:\n",
       "Zero-Shot Question Answering over Financial Documents usi ng Large Language\n",
       "Models. arXiv e-prints pp. arXiv–2311 (2023)\n",
       "40. Wu,S.,Irsoy,O.,Lu,S.,Dabravolski,V.,Dredze,M., Ge hrmann,S.,Kambadur,P.,\n",
       "Rosenberg, D., Mann, G.: BloombergGPT: A Large Language Mod el for Finance\n",
       "(2023)\n",
       "41. Xu, P., Ping, W., Wu, X., McAfee, L., Zhu, C., Liu, Z., Subr amanian, S., Bakhtu-\n",
       "rina,E.,Shoeybi,M.,Catanzaro, B.:RetrievalmeetsLongC ontextLargeLanguage\n",
       "Models (2023)\n",
       "42. Yang, H., Liu, X.Y., Wang, C.D.: FinGPT: Open-SourceFin ancial Large Language\n",
       "Models (2023)\n",
       "43.</span> <span style=\"color: magenta;\">Ye, H., Liu, T., Zhang, A., Hua, W., Jia, W.: Cognitive Mir age: A Review of\n",
       "Hallucinations in Large Language Models (2023)\n",
       "44. Zhang, B., Yang, H., Liu, X.Y.: Instruct-FinGPT: Financ ial Sentiment Analysis\n",
       "by Instruction Tuning of General-Purpose Large Language Mo dels (2023)\n",
       "45. Zheng, X., Burdick, D., Popa, L., Zhong, X., Wang, N.X.R. : Global table extractor\n",
       "(gte): A framework for joint table identiﬁcation and cell st ructure recognition using\n",
       "visual context. In: Proceedings of the IEEE/CVF winter conf erence on applications\n",
       "of computer vision. pp. 697–706 (2021)\n",
       "46. Zhu, F., Lei, W., Huang, Y., Wang, C., Zhang, S., Lv, J., Fe ng, F., Chua, T.S.:\n",
       "TAT-QA: A question answering benchmark on a hybrid of tabula r and textual\n",
       "content in ﬁnance. arXiv preprint arXiv:2105.07624 (2021)</span> </td>\n",
       "        </tr>\n",
       "        </tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_chunking_strategies_side_by_side(nltk_sentences, naive_chunks_text, flattened_semantic_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
